{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "acos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1W9x6RZVUA8Cpk-TCPfduxqKYLioSSgqM",
      "authorship_tag": "ABX9TyMIHKfNF2woTJrMYZAbQLhX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydmou/ABSA/blob/main/acos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMhvKGGqMbS4",
        "outputId": "5840ae06-9276-4194-ca6e-f9c337ea8343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtlSsGshSFCu",
        "outputId": "ddfcef5d-ee59-4bb3-94c5-f81b7c19c62e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ColabNotebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL_Kr_nmSLfy",
        "outputId": "bcaf72fd-17b4-4036-b759-187ae71aae34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3rtUTzrTDf6",
        "outputId": "c086abe2-e878-48da-b851-2e735a843e44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t3oJXbYdQEE",
        "outputId": "e62bc9b2-ccde-4690-d1d2-08b344b525ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.8.0\n",
            "Uninstalling torch-1.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==1.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "mKAdLZKyWZ6A",
        "outputId": "4df7542e-1aad-4db1-955a-d1e719294672"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLKy3vAKkNTQ",
        "outputId": "ed33ee81-bae7-4c53-82d6-c075ae36fe1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchpip as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping install as it is not installed.\u001b[0m\n",
            "Found existing installation: torch 1.8.0\n",
            "Uninstalling torch-1.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "KhGxTBzBT_bH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdpzlY77Xjlh",
        "outputId": "a1589441-a6c5-4128-ac23-6b6e799ccca2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.24.3)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.3 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.27.3)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.3->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.3->boto3) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.3->boto3) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-pretrained-bert\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlIBarIwY_Dh",
        "outputId": "e0306bd3-0c00-47b4-faa6-9e96a57848a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.8.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.2.0)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.3 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.27.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.3->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.3->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.3->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh run.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhsMzJItTMGg",
        "outputId": "4a017807-dc77-441a-ac48-dcc928e52d4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOMAIN is chosen from [rest16, laptop]\n",
            "Choosing the GPU device has largest free memory...\n",
            "Sorted by free memory size\n",
            "Sorted by free memory size\n",
            "Using GPU 0:\n",
            "index:0\n",
            "gpu_name:Tesla T4\n",
            "memory.free:15109\n",
            "memory.total:15109\n",
            "power.draw:10\n",
            "power.limit:70\n",
            "utilization.gpu:0 %\n",
            "specified:True\n",
            "06/07/2022 10:13:57 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/07/2022 10:13:57 - INFO - bert_utils.tokenization -   loading vocabulary file /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/BERT_BASE_DIR/vocab.txt\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   LOOKING AT /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/tokenized_data/rest16_test_quad_bert.tsv\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   Writing example 0 of 583\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: test-0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 5\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] yu ##m ! [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 9805 2213 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 5 4 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: test-1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 8\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] serves really good su ##shi . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 4240 2428 2204 10514 6182 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 5 3 2 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: test-2\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 9\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] not the biggest portions but adequate . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2025 1996 5221 8810 2021 11706 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 5 4 4 3 1 5 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: test-3\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 13\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] green tea cr ##eme br ##ule ##e is a must ! [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2665 5572 13675 21382 7987 9307 2063 2003 1037 2442 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 3 2 2 2 2 2 2 1 1 5 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: test-4\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 12\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] it has great su ##shi and even better service . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2009 2038 2307 10514 6182 1998 2130 2488 2326 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 5 3 2 1 1 5 3 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   LOOKING AT /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/tokenized_data/rest16_train_quad_bert.tsv\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   Writing example 0 of 1530\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: train-0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 19\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] judging from previous posts this used to be a good place , but not any longer . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 13325 2013 3025 8466 2023 2109 2000 2022 1037 2204 2173 1010 2021 2025 2151 2936 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 1 1 1 1 1 1 1 1 3 1 1 5 4 4 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: train-1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 35\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] we , there were four of us , arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2057 1010 2045 2020 2176 1997 2149 1010 3369 2012 11501 1011 1996 2173 2001 4064 1011 1998 1996 3095 6051 2066 2057 2020 16625 2006 2068 1998 2027 2020 2200 12726 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 5 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: train-2\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 24\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] they never brought us compliment ##ary noodles , ignored repeated requests for sugar , and threw our dishes on the table . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2027 2196 2716 2149 19394 5649 27130 1010 6439 5567 11186 2005 5699 1010 1998 4711 2256 10447 2006 1996 2795 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: train-3\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 18\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] the food was lou ##sy - too sweet or too salty and the portions tiny . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 1996 2833 2001 10223 6508 1011 2205 4086 2030 2205 23592 1998 1996 8810 4714 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 3 1 5 4 1 5 4 1 5 4 1 1 3 5 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: train-4\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 15\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] after all that , they complained to me about the small tip . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2044 2035 2008 1010 2027 10865 2000 2033 2055 1996 2235 5955 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 1 1 1 5 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   LOOKING AT /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/tokenized_data/rest16_dev_quad_bert.tsv\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   Writing example 0 of 171\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: valid-0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 13\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] ca n ' t wait wait for my next visit . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 6187 1050 1005 1056 3524 3524 2005 2026 2279 3942 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: valid-1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 29\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] their sake list was extensive , but we were looking for purple haze , which was n ' t listed but made for us upon request ! [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2037 8739 2862 2001 4866 1010 2021 2057 2020 2559 2005 6379 16332 1010 2029 2001 1050 1005 1056 3205 2021 2081 2005 2149 2588 5227 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 3 2 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: valid-2\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 26\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] the spicy tuna roll was unusually good and the rock shrimp te ##mp ##ura was awesome , great app ##eti ##zer to share ! [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 1996 25482 24799 4897 2001 12890 2204 1998 1996 2600 20130 8915 8737 4648 2001 12476 1010 2307 10439 20624 6290 2000 3745 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 3 2 2 1 1 5 1 1 3 2 2 2 2 1 5 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: valid-3\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 8\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] we love th pink pony . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2057 2293 16215 5061 15606 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 5 1 3 2 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: valid-4\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   tokens_len: 18\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   guid: 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] this place has got to be the best japanese restaurant in the new york area . [CLS]\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2023 2173 2038 2288 2000 2022 1996 2190 2887 4825 1999 1996 2047 2259 2181 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_ids: 0 1 3 1 1 1 1 1 5 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/07/2022 10:13:57 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:13:57 - INFO - __main__ -   ***** Running training *****\n",
            "06/07/2022 10:13:57 - INFO - __main__ -     Num examples = 1530\n",
            "06/07/2022 10:13:57 - INFO - __main__ -     Batch size = 24\n",
            "Traceback (most recent call last):\n",
            "  File \"run_step1.py\", line 481, in <module>\n",
            "    main()\n",
            "  File \"run_step1.py\", line 353, in main\n",
            "    model = model_dict[args.model_type].from_pretrained(args.bert_model, num_labels=num_labels)\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/modeling.py\", line 718, in from_pretrained\n",
            "    model = cls(config, *inputs, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/modeling.py\", line 1552, in __init__\n",
            "    self.crf = CRF(self.crf_num, batch_first=True)\n",
            "NameError: name 'CRF' is not defined\n",
            "Traceback (most recent call last):\n",
            "  File \"tokenized_data/get_1st_pairs.py\", line 15, in <module>\n",
            "    f = cs.open(cur_dir+'_1st'+'/pred4pipeline.txt', 'r').readlines()\n",
            "  File \"/usr/lib/python3.7/codecs.py\", line 904, in open\n",
            "    file = builtins.open(filename, mode, buffering)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/BASE_DIR/output/Extract-Classify-QUAD/rest16_1st/pred4pipeline.txt'\n",
            "Choosing the GPU device has largest free memory...\n",
            "Sorted by free memory size\n",
            "Sorted by free memory size\n",
            "Using GPU 0:\n",
            "index:0\n",
            "gpu_name:Tesla T4\n",
            "memory.free:15109\n",
            "memory.total:15109\n",
            "power.draw:9\n",
            "power.limit:70\n",
            "utilization.gpu:0 %\n",
            "specified:True\n",
            "06/07/2022 10:14:02 - INFO - bert_utils.tokenization -   loading vocabulary file /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/BERT_BASE_DIR/vocab.txt\n",
            "06/07/2022 10:14:02 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/BERT_BASE_DIR/vocab.txt\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   Writing example 0 of 1346\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   guid: test-0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   tokens_len: 5\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] yu ##m ! [CLS]\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 9805 2213 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_aspect: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   guid: test-1\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   tokens_len: 8\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] serves really good su ##shi . [CLS]\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 4240 2428 2204 10514 6182 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   guid: test-2\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   tokens_len: 9\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] not the biggest portions but adequate . [CLS]\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2025 1996 5221 8810 2021 11706 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   guid: test-3\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   tokens_len: 9\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] not the biggest portions but adequate . [CLS]\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2025 1996 5221 8810 2021 11706 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   guid: test-4\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   tokens_len: 13\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] green tea cr ##eme br ##ule ##e is a must ! [CLS]\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2665 5572 13675 21382 7987 9307 2063 2003 1037 2442 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:02 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   LOOKING AT /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/tokenized_data/rest16_train_pair.tsv\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   Writing example 0 of 2419\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: train-0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 19\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] judging from previous posts this used to be a good place , but not any longer . [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 13325 2013 3025 8466 2023 2109 2000 2022 1037 2204 2173 1010 2021 2025 2151 2936 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: train-1\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 35\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] we , there were four of us , arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude . [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2057 1010 2045 2020 2176 1997 2149 1010 3369 2012 11501 1011 1996 2173 2001 4064 1011 1998 1996 3095 6051 2066 2057 2020 16625 2006 2068 1998 2027 2020 2200 12726 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: train-2\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 24\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] they never brought us compliment ##ary noodles , ignored repeated requests for sugar , and threw our dishes on the table . [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2027 2196 2716 2149 19394 5649 27130 1010 6439 5567 11186 2005 5699 1010 1998 4711 2256 10447 2006 1996 2795 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: train-3\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 18\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] the food was lou ##sy - too sweet or too salty and the portions tiny . [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 1996 2833 2001 10223 6508 1011 2205 4086 2030 2205 23592 1998 1996 8810 4714 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: train-4\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 18\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] the food was lou ##sy - too sweet or too salty and the portions tiny . [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 1996 2833 2001 10223 6508 1011 2205 4086 2030 2205 23592 1998 1996 8810 4714 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   LOOKING AT /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/Extract-Classify-ACOS/tokenized_data/rest16_dev_pair.tsv\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   Writing example 0 of 251\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: valid-0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 13\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] ca n ' t wait wait for my next visit . [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 6187 1050 1005 1056 3524 3524 2005 2026 2279 3942 1012 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: valid-1\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 29\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] their sake list was extensive , but we were looking for purple haze , which was n ' t listed but made for us upon request ! [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2037 8739 2862 2001 4866 1010 2021 2057 2020 2559 2005 6379 16332 1010 2029 2001 1050 1005 1056 3205 2021 2081 2005 2149 2588 5227 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: valid-2\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 29\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] their sake list was extensive , but we were looking for purple haze , which was n ' t listed but made for us upon request ! [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 2037 8739 2862 2001 4866 1010 2021 2057 2020 2559 2005 6379 16332 1010 2029 2001 1050 1005 1056 3205 2021 2081 2005 2149 2588 5227 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: valid-3\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 26\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] the spicy tuna roll was unusually good and the rock shrimp te ##mp ##ura was awesome , great app ##eti ##zer to share ! [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 1996 25482 24799 4897 2001 12890 2204 1998 1996 2600 20130 8915 8737 4648 2001 12476 1010 2307 10439 20624 6290 2000 3745 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   guid: valid-4\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   tokens_len: 26\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect tokens: [CLS] the spicy tuna roll was unusually good and the rock shrimp te ##mp ##ura was awesome , great app ##eti ##zer to share ! [CLS]\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_ids: 101 1996 25482 24799 4897 2001 12890 2204 1998 1996 2600 20130 8915 8737 4648 2001 12476 1010 2307 10439 20624 6290 2000 3745 999 101 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   aspect_segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_aspect: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   candidate_opinion: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - run_classifier_dataset_utils -   label_id: 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "06/07/2022 10:14:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /content/drive/MyDrive/ColabNotebooks/BASE_DIR/ACOS-main/BERT_BASE_DIR/vocab.txt\n",
            "06/07/2022 10:14:03 - INFO - __main__ -   ***** Running training *****\n",
            "Epoch:   0% 0/10 [00:00<?, ?it/s]06/07/2022 10:14:10 - INFO - __main__ -   Total Loss is 0.7143717408180237 .\n",
            "06/07/2022 10:14:12 - INFO - __main__ -   Total Loss is 0.5174506902694702 .\n",
            "06/07/2022 10:14:15 - INFO - __main__ -   Total Loss is 0.2270849645137787 .\n",
            "06/07/2022 10:14:17 - INFO - __main__ -   Total Loss is 0.15570853650569916 .\n",
            "06/07/2022 10:14:19 - INFO - __main__ -   Total Loss is 0.13103461265563965 .\n",
            "06/07/2022 10:14:22 - INFO - __main__ -   Total Loss is 0.11311744153499603 .\n",
            "06/07/2022 10:14:24 - INFO - __main__ -   Total Loss is 0.11048654466867447 .\n",
            "06/07/2022 10:14:26 - INFO - __main__ -   Total Loss is 0.10843820124864578 .\n",
            "06/07/2022 10:14:29 - INFO - __main__ -   Total Loss is 0.10915881395339966 .\n",
            "06/07/2022 10:14:31 - INFO - __main__ -   Total Loss is 0.10250148922204971 .\n",
            "06/07/2022 10:14:33 - INFO - __main__ -   Total Loss is 0.09401481598615646 .\n",
            "06/07/2022 10:14:36 - INFO - __main__ -   Total Loss is 0.1019015982747078 .\n",
            "06/07/2022 10:14:38 - INFO - __main__ -   Total Loss is 0.09496248513460159 .\n",
            "06/07/2022 10:14:40 - INFO - __main__ -   Total Loss is 0.09482782334089279 .\n",
            "06/07/2022 10:14:43 - INFO - __main__ -   Total Loss is 0.08853039145469666 .\n",
            "06/07/2022 10:14:45 - INFO - __main__ -   Total Loss is 0.09215626120567322 .\n",
            "Quad num: 0\n",
            "tp: 0.0. fp: 0.0. fn: 251.0.\n",
            "06/07/2022 10:14:47 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:14:47 - INFO - __main__ -     micro-F1 = 0\n",
            "06/07/2022 10:14:47 - INFO - __main__ -     precision = 0\n",
            "06/07/2022 10:14:47 - INFO - __main__ -     recall = 0.0\n",
            "Quad num: 0\n",
            "tp: 0.0. fp: 0.0. fn: 895.0.\n",
            "tp: 0.0. fp: 0.0. fn: 490.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 142.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 98.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 102.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 715.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 399.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 123.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 85.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 95.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 623.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** sentiment results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 497.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 144.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 101.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 103.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 725.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category sentiment results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 580.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 153.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 139.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 98.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 804.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** aspect results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 596.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 160.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 144.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 103.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 827.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category aspect results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 589.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 158.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 141.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 101.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 818.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** sentiment aspect results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 600.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 161.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 145.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 103.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 832.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category sentiment aspect results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 580.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 150.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 113.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 102.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 811.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 595.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 154.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 116.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 103.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 827.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 580.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 150.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 114.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 103.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 812.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** sentiment opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 595.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 154.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 117.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 104.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 828.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category sentiment opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 659.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 167.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 147.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 104.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 895.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** aspect opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 659.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 167.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 147.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 104.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 895.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category aspect opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 659.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 167.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 147.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 104.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 895.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** sentiment aspect opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "tp: 0.0. fp: 0.0. fn: 659.0.\n",
            "0 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 167.0.\n",
            "1 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 147.0.\n",
            "2 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 104.0.\n",
            "3 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "tp: 0.0. fp: 0.0. fn: 895.0.\n",
            "4 :  {'precision': 0, 'recall': 0.0, 'micro-F1': 0}\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** category sentiment aspect opinion results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.00%\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   -----------------------------------\n",
            "06/07/2022 10:14:53 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     micro-F1 = 0\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     precision = 0\n",
            "06/07/2022 10:14:53 - INFO - __main__ -     recall = 0.0\n",
            "Epoch:  10% 1/10 [00:43<06:30, 43.42s/it]06/07/2022 10:14:53 - INFO - __main__ -   Total Loss is 0.0998310074210167 .\n",
            "06/07/2022 10:14:56 - INFO - __main__ -   Total Loss is 0.09191499650478363 .\n",
            "06/07/2022 10:14:59 - INFO - __main__ -   Total Loss is 0.0880565196275711 .\n",
            "06/07/2022 10:15:01 - INFO - __main__ -   Total Loss is 0.08092738687992096 .\n",
            "06/07/2022 10:15:04 - INFO - __main__ -   Total Loss is 0.08068929612636566 .\n",
            "06/07/2022 10:15:06 - INFO - __main__ -   Total Loss is 0.08853281289339066 .\n",
            "06/07/2022 10:15:09 - INFO - __main__ -   Total Loss is 0.07313209772109985 .\n",
            "06/07/2022 10:15:11 - INFO - __main__ -   Total Loss is 0.06203221157193184 .\n",
            "06/07/2022 10:15:14 - INFO - __main__ -   Total Loss is 0.0681457445025444 .\n",
            "06/07/2022 10:15:16 - INFO - __main__ -   Total Loss is 0.05375395715236664 .\n",
            "06/07/2022 10:15:19 - INFO - __main__ -   Total Loss is 0.08007483184337616 .\n",
            "06/07/2022 10:15:21 - INFO - __main__ -   Total Loss is 0.08399925380945206 .\n",
            "06/07/2022 10:15:23 - INFO - __main__ -   Total Loss is 0.0830877274274826 .\n",
            "06/07/2022 10:15:26 - INFO - __main__ -   Total Loss is 0.04933450371026993 .\n",
            "06/07/2022 10:15:28 - INFO - __main__ -   Total Loss is 0.08620959520339966 .\n",
            "06/07/2022 10:15:30 - INFO - __main__ -   Total Loss is 0.06819295138120651 .\n",
            "Quad num: 151\n",
            "tp: 106.0. fp: 45.0. fn: 145.0.\n",
            "06/07/2022 10:15:31 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:15:31 - INFO - __main__ -     micro-F1 = 0.527363184079602\n",
            "06/07/2022 10:15:31 - INFO - __main__ -     precision = 0.7019867549668874\n",
            "06/07/2022 10:15:31 - INFO - __main__ -     recall = 0.42231075697211157\n",
            "Quad num: 778\n",
            "tp: 339.0. fp: 439.0. fn: 556.0.\n",
            "tp: 257.0. fp: 38.0. fn: 233.0.\n",
            "0 :  {'precision': 0.8711864406779661, 'recall': 0.5244897959183673, 'micro-F1': 0.6547770700636942}\n",
            "tp: 49.0. fp: 11.0. fn: 93.0.\n",
            "1 :  {'precision': 0.8166666666666667, 'recall': 0.34507042253521125, 'micro-F1': 0.48514851485148514}\n",
            "tp: 43.0. fp: 6.0. fn: 55.0.\n",
            "2 :  {'precision': 0.8775510204081632, 'recall': 0.4387755102040816, 'micro-F1': 0.585034013605442}\n",
            "tp: 40.0. fp: 6.0. fn: 62.0.\n",
            "3 :  {'precision': 0.8695652173913043, 'recall': 0.39215686274509803, 'micro-F1': 0.5405405405405406}\n",
            "tp: 348.0. fp: 57.0. fn: 367.0.\n",
            "4 :  {'precision': 0.8592592592592593, 'recall': 0.48671328671328673, 'micro-F1': 0.6214285714285714}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 62.14%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 85.93%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 48.67%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 267.0. fp: 14.0. fn: 132.0.\n",
            "0 :  {'precision': 0.9501779359430605, 'recall': 0.6691729323308271, 'micro-F1': 0.7852941176470588}\n",
            "tp: 53.0. fp: 5.0. fn: 70.0.\n",
            "1 :  {'precision': 0.9137931034482759, 'recall': 0.43089430894308944, 'micro-F1': 0.585635359116022}\n",
            "tp: 38.0. fp: 11.0. fn: 47.0.\n",
            "2 :  {'precision': 0.7755102040816326, 'recall': 0.4470588235294118, 'micro-F1': 0.5671641791044777}\n",
            "tp: 33.0. fp: 14.0. fn: 62.0.\n",
            "3 :  {'precision': 0.7021276595744681, 'recall': 0.3473684210526316, 'micro-F1': 0.46478873239436624}\n",
            "tp: 350.0. fp: 42.0. fn: 273.0.\n",
            "4 :  {'precision': 0.8928571428571429, 'recall': 0.5617977528089888, 'micro-F1': 0.6896551724137933}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** sentiment results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 68.97%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 89.29%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 56.18%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 240.0. fp: 55.0. fn: 257.0.\n",
            "0 :  {'precision': 0.8135593220338984, 'recall': 0.482897384305835, 'micro-F1': 0.606060606060606}\n",
            "tp: 44.0. fp: 16.0. fn: 100.0.\n",
            "1 :  {'precision': 0.7333333333333333, 'recall': 0.3055555555555556, 'micro-F1': 0.43137254901960786}\n",
            "tp: 32.0. fp: 17.0. fn: 69.0.\n",
            "2 :  {'precision': 0.6530612244897959, 'recall': 0.31683168316831684, 'micro-F1': 0.4266666666666667}\n",
            "tp: 31.0. fp: 16.0. fn: 72.0.\n",
            "3 :  {'precision': 0.6595744680851063, 'recall': 0.30097087378640774, 'micro-F1': 0.4133333333333333}\n",
            "tp: 311.0. fp: 95.0. fn: 414.0.\n",
            "4 :  {'precision': 0.7660098522167488, 'recall': 0.4289655172413793, 'micro-F1': 0.5499557913351018}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category sentiment results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 55.00%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 76.60%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 42.90%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 345.0. fp: 64.0. fn: 235.0.\n",
            "0 :  {'precision': 0.843520782396088, 'recall': 0.5948275862068966, 'micro-F1': 0.6976744186046511}\n",
            "tp: 71.0. fp: 9.0. fn: 82.0.\n",
            "1 :  {'precision': 0.8875, 'recall': 0.46405228758169936, 'micro-F1': 0.6094420600858369}\n",
            "tp: 63.0. fp: 16.0. fn: 76.0.\n",
            "2 :  {'precision': 0.7974683544303798, 'recall': 0.45323741007194246, 'micro-F1': 0.5779816513761469}\n",
            "tp: 45.0. fp: 2.0. fn: 53.0.\n",
            "3 :  {'precision': 0.9574468085106383, 'recall': 0.45918367346938777, 'micro-F1': 0.6206896551724138}\n",
            "tp: 444.0. fp: 83.0. fn: 360.0.\n",
            "4 :  {'precision': 0.8425047438330171, 'recall': 0.5522388059701493, 'micro-F1': 0.6671675432006011}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** aspect results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 66.72%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 84.25%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 55.22%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 288.0. fp: 121.0. fn: 308.0.\n",
            "0 :  {'precision': 0.7041564792176039, 'recall': 0.48322147651006714, 'micro-F1': 0.573134328358209}\n",
            "tp: 57.0. fp: 23.0. fn: 103.0.\n",
            "1 :  {'precision': 0.7125, 'recall': 0.35625, 'micro-F1': 0.475}\n",
            "tp: 53.0. fp: 26.0. fn: 91.0.\n",
            "2 :  {'precision': 0.6708860759493671, 'recall': 0.3680555555555556, 'micro-F1': 0.47533632286995514}\n",
            "tp: 39.0. fp: 8.0. fn: 64.0.\n",
            "3 :  {'precision': 0.8297872340425532, 'recall': 0.3786407766990291, 'micro-F1': 0.52}\n",
            "tp: 370.0. fp: 157.0. fn: 457.0.\n",
            "4 :  {'precision': 0.7020872865275142, 'recall': 0.44740024183796856, 'micro-F1': 0.5465288035450517}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category aspect results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 54.65%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 70.21%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 44.74%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 328.0. fp: 81.0. fn: 261.0.\n",
            "0 :  {'precision': 0.8019559902200489, 'recall': 0.5568760611205433, 'micro-F1': 0.657314629258517}\n",
            "tp: 64.0. fp: 16.0. fn: 94.0.\n",
            "1 :  {'precision': 0.8, 'recall': 0.4050632911392405, 'micro-F1': 0.5378151260504201}\n",
            "tp: 51.0. fp: 28.0. fn: 90.0.\n",
            "2 :  {'precision': 0.6455696202531646, 'recall': 0.3617021276595745, 'micro-F1': 0.4636363636363637}\n",
            "tp: 31.0. fp: 17.0. fn: 70.0.\n",
            "3 :  {'precision': 0.6458333333333334, 'recall': 0.3069306930693069, 'micro-F1': 0.41610738255033564}\n",
            "tp: 399.0. fp: 129.0. fn: 419.0.\n",
            "4 :  {'precision': 0.7556818181818182, 'recall': 0.4877750611246944, 'micro-F1': 0.5928677563150074}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** sentiment aspect results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 59.29%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 75.57%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 48.78%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 274.0. fp: 135.0. fn: 326.0.\n",
            "0 :  {'precision': 0.6699266503667481, 'recall': 0.45666666666666667, 'micro-F1': 0.5431119920713577}\n",
            "tp: 52.0. fp: 28.0. fn: 109.0.\n",
            "1 :  {'precision': 0.65, 'recall': 0.32298136645962733, 'micro-F1': 0.43153526970954353}\n",
            "tp: 43.0. fp: 36.0. fn: 102.0.\n",
            "2 :  {'precision': 0.5443037974683544, 'recall': 0.296551724137931, 'micro-F1': 0.38392857142857145}\n",
            "tp: 29.0. fp: 19.0. fn: 74.0.\n",
            "3 :  {'precision': 0.6041666666666666, 'recall': 0.2815533980582524, 'micro-F1': 0.3841059602649006}\n",
            "tp: 336.0. fp: 192.0. fn: 496.0.\n",
            "4 :  {'precision': 0.6363636363636364, 'recall': 0.40384615384615385, 'micro-F1': 0.4941176470588235}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category sentiment aspect results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 49.41%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 63.64%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 40.38%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 367.0. fp: 56.0. fn: 213.0.\n",
            "0 :  {'precision': 0.8676122931442081, 'recall': 0.6327586206896552, 'micro-F1': 0.7318045862412761}\n",
            "tp: 61.0. fp: 13.0. fn: 89.0.\n",
            "1 :  {'precision': 0.8243243243243243, 'recall': 0.4066666666666667, 'micro-F1': 0.5446428571428571}\n",
            "tp: 48.0. fp: 12.0. fn: 65.0.\n",
            "2 :  {'precision': 0.8, 'recall': 0.4247787610619469, 'micro-F1': 0.5549132947976878}\n",
            "tp: 43.0. fp: 5.0. fn: 59.0.\n",
            "3 :  {'precision': 0.8958333333333334, 'recall': 0.4215686274509804, 'micro-F1': 0.5733333333333334}\n",
            "tp: 462.0. fp: 78.0. fn: 349.0.\n",
            "4 :  {'precision': 0.8555555555555555, 'recall': 0.5696670776818742, 'micro-F1': 0.6839378238341968}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 68.39%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 85.56%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 56.97%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 293.0. fp: 140.0. fn: 302.0.\n",
            "0 :  {'precision': 0.6766743648960739, 'recall': 0.492436974789916, 'micro-F1': 0.5700389105058365}\n",
            "tp: 44.0. fp: 30.0. fn: 110.0.\n",
            "1 :  {'precision': 0.5945945945945946, 'recall': 0.2857142857142857, 'micro-F1': 0.38596491228070173}\n",
            "tp: 39.0. fp: 21.0. fn: 77.0.\n",
            "2 :  {'precision': 0.65, 'recall': 0.33620689655172414, 'micro-F1': 0.44318181818181823}\n",
            "tp: 37.0. fp: 11.0. fn: 66.0.\n",
            "3 :  {'precision': 0.7708333333333334, 'recall': 0.3592233009708738, 'micro-F1': 0.490066225165563}\n",
            "tp: 373.0. fp: 177.0. fn: 454.0.\n",
            "4 :  {'precision': 0.6781818181818182, 'recall': 0.45102781136638453, 'micro-F1': 0.5417574437182281}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 54.18%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 67.82%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 45.10%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 349.0. fp: 74.0. fn: 231.0.\n",
            "0 :  {'precision': 0.8250591016548463, 'recall': 0.6017241379310345, 'micro-F1': 0.6959122632103689}\n",
            "tp: 58.0. fp: 16.0. fn: 92.0.\n",
            "1 :  {'precision': 0.7837837837837838, 'recall': 0.38666666666666666, 'micro-F1': 0.5178571428571429}\n",
            "tp: 40.0. fp: 20.0. fn: 74.0.\n",
            "2 :  {'precision': 0.6666666666666666, 'recall': 0.3508771929824561, 'micro-F1': 0.4597701149425287}\n",
            "tp: 30.0. fp: 19.0. fn: 73.0.\n",
            "3 :  {'precision': 0.6122448979591837, 'recall': 0.2912621359223301, 'micro-F1': 0.39473684210526316}\n",
            "tp: 423.0. fp: 118.0. fn: 389.0.\n",
            "4 :  {'precision': 0.7818853974121996, 'recall': 0.520935960591133, 'micro-F1': 0.6252771618625278}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** sentiment opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 62.53%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 78.19%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 52.09%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 280.0. fp: 153.0. fn: 315.0.\n",
            "0 :  {'precision': 0.6466512702078522, 'recall': 0.47058823529411764, 'micro-F1': 0.5447470817120623}\n",
            "tp: 42.0. fp: 32.0. fn: 112.0.\n",
            "1 :  {'precision': 0.5675675675675675, 'recall': 0.2727272727272727, 'micro-F1': 0.3684210526315789}\n",
            "tp: 32.0. fp: 28.0. fn: 85.0.\n",
            "2 :  {'precision': 0.5333333333333333, 'recall': 0.27350427350427353, 'micro-F1': 0.36158192090395486}\n",
            "tp: 28.0. fp: 21.0. fn: 76.0.\n",
            "3 :  {'precision': 0.5714285714285714, 'recall': 0.2692307692307692, 'micro-F1': 0.3660130718954248}\n",
            "tp: 344.0. fp: 207.0. fn: 484.0.\n",
            "4 :  {'precision': 0.6243194192377496, 'recall': 0.41545893719806765, 'micro-F1': 0.498912255257433}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category sentiment opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 49.89%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 62.43%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 41.55%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 351.0. fp: 298.0. fn: 308.0.\n",
            "0 :  {'precision': 0.5408320493066255, 'recall': 0.5326251896813353, 'micro-F1': 0.536697247706422}\n",
            "tp: 61.0. fp: 41.0. fn: 106.0.\n",
            "1 :  {'precision': 0.5980392156862745, 'recall': 0.3652694610778443, 'micro-F1': 0.45353159851301117}\n",
            "tp: 43.0. fp: 70.0. fn: 104.0.\n",
            "2 :  {'precision': 0.3805309734513274, 'recall': 0.2925170068027211, 'micro-F1': 0.3307692307692307}\n",
            "tp: 42.0. fp: 7.0. fn: 62.0.\n",
            "3 :  {'precision': 0.8571428571428571, 'recall': 0.40384615384615385, 'micro-F1': 0.5490196078431373}\n",
            "tp: 433.0. fp: 344.0. fn: 462.0.\n",
            "4 :  {'precision': 0.5572715572715573, 'recall': 0.48379888268156424, 'micro-F1': 0.5179425837320575}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** aspect opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 51.79%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 55.73%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 48.38%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 295.0. fp: 354.0. fn: 364.0.\n",
            "0 :  {'precision': 0.45454545454545453, 'recall': 0.44764795144157815, 'micro-F1': 0.45107033639143734}\n",
            "tp: 50.0. fp: 52.0. fn: 117.0.\n",
            "1 :  {'precision': 0.49019607843137253, 'recall': 0.2994011976047904, 'micro-F1': 0.37174721189591076}\n",
            "tp: 36.0. fp: 77.0. fn: 111.0.\n",
            "2 :  {'precision': 0.3185840707964602, 'recall': 0.24489795918367346, 'micro-F1': 0.2769230769230769}\n",
            "tp: 36.0. fp: 13.0. fn: 68.0.\n",
            "3 :  {'precision': 0.7346938775510204, 'recall': 0.34615384615384615, 'micro-F1': 0.47058823529411764}\n",
            "tp: 364.0. fp: 413.0. fn: 531.0.\n",
            "4 :  {'precision': 0.46846846846846846, 'recall': 0.40670391061452515, 'micro-F1': 0.4354066985645933}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category aspect opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 43.54%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 46.85%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 40.67%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 338.0. fp: 311.0. fn: 321.0.\n",
            "0 :  {'precision': 0.5208012326656395, 'recall': 0.5128983308042488, 'micro-F1': 0.5168195718654434}\n",
            "tp: 59.0. fp: 43.0. fn: 108.0.\n",
            "1 :  {'precision': 0.5784313725490197, 'recall': 0.3532934131736527, 'micro-F1': 0.4386617100371747}\n",
            "tp: 36.0. fp: 77.0. fn: 111.0.\n",
            "2 :  {'precision': 0.3185840707964602, 'recall': 0.24489795918367346, 'micro-F1': 0.2769230769230769}\n",
            "tp: 28.0. fp: 22.0. fn: 76.0.\n",
            "3 :  {'precision': 0.56, 'recall': 0.2692307692307692, 'micro-F1': 0.36363636363636365}\n",
            "tp: 400.0. fp: 378.0. fn: 495.0.\n",
            "4 :  {'precision': 0.5141388174807198, 'recall': 0.44692737430167595, 'micro-F1': 0.4781829049611476}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** sentiment aspect opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 47.82%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 51.41%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 44.69%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "tp: 285.0. fp: 364.0. fn: 374.0.\n",
            "0 :  {'precision': 0.4391371340523883, 'recall': 0.4324734446130501, 'micro-F1': 0.4357798165137614}\n",
            "tp: 48.0. fp: 54.0. fn: 119.0.\n",
            "1 :  {'precision': 0.47058823529411764, 'recall': 0.2874251497005988, 'micro-F1': 0.35687732342007433}\n",
            "tp: 30.0. fp: 83.0. fn: 117.0.\n",
            "2 :  {'precision': 0.26548672566371684, 'recall': 0.20408163265306123, 'micro-F1': 0.23076923076923078}\n",
            "tp: 26.0. fp: 24.0. fn: 78.0.\n",
            "3 :  {'precision': 0.52, 'recall': 0.25, 'micro-F1': 0.33766233766233766}\n",
            "tp: 339.0. fp: 439.0. fn: 556.0.\n",
            "4 :  {'precision': 0.43573264781491, 'recall': 0.3787709497206704, 'micro-F1': 0.4052600119545726}\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   ***** category sentiment aspect opinion results *****\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     micro-F1 = 40.53%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     precision = 43.57%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -     recall = 37.88%\n",
            "06/07/2022 10:15:37 - INFO - __main__ -   -----------------------------------\n",
            "06/07/2022 10:15:38 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:15:38 - INFO - __main__ -     micro-F1 = 0.4052600119545726\n",
            "06/07/2022 10:15:38 - INFO - __main__ -     precision = 0.43573264781491\n",
            "06/07/2022 10:15:38 - INFO - __main__ -     recall = 0.3787709497206704\n",
            "Epoch:  20% 2/10 [01:27<05:52, 44.07s/it]06/07/2022 10:15:38 - INFO - __main__ -   Total Loss is 0.0465150810778141 .\n",
            "06/07/2022 10:15:41 - INFO - __main__ -   Total Loss is 0.060412682592868805 .\n",
            "06/07/2022 10:15:43 - INFO - __main__ -   Total Loss is 0.05286352336406708 .\n",
            "06/07/2022 10:15:46 - INFO - __main__ -   Total Loss is 0.059089295566082 .\n",
            "06/07/2022 10:15:49 - INFO - __main__ -   Total Loss is 0.07495732605457306 .\n",
            "06/07/2022 10:15:51 - INFO - __main__ -   Total Loss is 0.07224371284246445 .\n",
            "06/07/2022 10:15:53 - INFO - __main__ -   Total Loss is 0.04848695918917656 .\n",
            "06/07/2022 10:15:56 - INFO - __main__ -   Total Loss is 0.04201411083340645 .\n",
            "06/07/2022 10:15:58 - INFO - __main__ -   Total Loss is 0.058872200548648834 .\n",
            "06/07/2022 10:16:01 - INFO - __main__ -   Total Loss is 0.06700613349676132 .\n",
            "06/07/2022 10:16:03 - INFO - __main__ -   Total Loss is 0.05613961070775986 .\n",
            "06/07/2022 10:16:06 - INFO - __main__ -   Total Loss is 0.047444287687540054 .\n",
            "06/07/2022 10:16:08 - INFO - __main__ -   Total Loss is 0.042045433074235916 .\n",
            "06/07/2022 10:16:11 - INFO - __main__ -   Total Loss is 0.05422237142920494 .\n",
            "06/07/2022 10:16:13 - INFO - __main__ -   Total Loss is 0.031147383153438568 .\n",
            "06/07/2022 10:16:16 - INFO - __main__ -   Total Loss is 0.0424191951751709 .\n",
            "Quad num: 183\n",
            "tp: 138.0. fp: 45.0. fn: 113.0.\n",
            "06/07/2022 10:16:17 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:16:17 - INFO - __main__ -     micro-F1 = 0.6359447004608294\n",
            "06/07/2022 10:16:17 - INFO - __main__ -     precision = 0.7540983606557377\n",
            "06/07/2022 10:16:17 - INFO - __main__ -     recall = 0.549800796812749\n",
            "Quad num: 975\n",
            "tp: 418.0. fp: 557.0. fn: 477.0.\n",
            "tp: 321.0. fp: 51.0. fn: 169.0.\n",
            "0 :  {'precision': 0.8629032258064516, 'recall': 0.6551020408163265, 'micro-F1': 0.7447795823665894}\n",
            "tp: 65.0. fp: 11.0. fn: 77.0.\n",
            "1 :  {'precision': 0.8552631578947368, 'recall': 0.45774647887323944, 'micro-F1': 0.5963302752293578}\n",
            "tp: 52.0. fp: 9.0. fn: 46.0.\n",
            "2 :  {'precision': 0.8524590163934426, 'recall': 0.5306122448979592, 'micro-F1': 0.6540880503144654}\n",
            "tp: 52.0. fp: 8.0. fn: 50.0.\n",
            "3 :  {'precision': 0.8666666666666667, 'recall': 0.5098039215686274, 'micro-F1': 0.6419753086419753}\n",
            "tp: 436.0. fp: 72.0. fn: 279.0.\n",
            "4 :  {'precision': 0.8582677165354331, 'recall': 0.6097902097902098, 'micro-F1': 0.7130008176614883}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 71.30%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 85.83%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 60.98%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 311.0. fp: 32.0. fn: 88.0.\n",
            "0 :  {'precision': 0.9067055393586005, 'recall': 0.7794486215538847, 'micro-F1': 0.8382749326145552}\n",
            "tp: 66.0. fp: 4.0. fn: 57.0.\n",
            "1 :  {'precision': 0.9428571428571428, 'recall': 0.5365853658536586, 'micro-F1': 0.6839378238341969}\n",
            "tp: 48.0. fp: 13.0. fn: 37.0.\n",
            "2 :  {'precision': 0.7868852459016393, 'recall': 0.5647058823529412, 'micro-F1': 0.6575342465753424}\n",
            "tp: 47.0. fp: 15.0. fn: 48.0.\n",
            "3 :  {'precision': 0.7580645161290323, 'recall': 0.49473684210526314, 'micro-F1': 0.5987261146496815}\n",
            "tp: 420.0. fp: 61.0. fn: 203.0.\n",
            "4 :  {'precision': 0.8731808731808732, 'recall': 0.6741573033707865, 'micro-F1': 0.7608695652173912}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** sentiment results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 76.09%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 87.32%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 67.42%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 298.0. fp: 82.0. fn: 199.0.\n",
            "0 :  {'precision': 0.7842105263157895, 'recall': 0.5995975855130785, 'micro-F1': 0.6795895096921323}\n",
            "tp: 62.0. fp: 14.0. fn: 82.0.\n",
            "1 :  {'precision': 0.8157894736842105, 'recall': 0.4305555555555556, 'micro-F1': 0.5636363636363637}\n",
            "tp: 43.0. fp: 19.0. fn: 58.0.\n",
            "2 :  {'precision': 0.6935483870967742, 'recall': 0.42574257425742573, 'micro-F1': 0.5276073619631902}\n",
            "tp: 43.0. fp: 19.0. fn: 60.0.\n",
            "3 :  {'precision': 0.6935483870967742, 'recall': 0.4174757281553398, 'micro-F1': 0.5212121212121212}\n",
            "tp: 394.0. fp: 124.0. fn: 331.0.\n",
            "4 :  {'precision': 0.7606177606177607, 'recall': 0.543448275862069, 'micro-F1': 0.6339501206757845}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category sentiment results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 63.40%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 76.06%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 54.34%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 405.0. fp: 90.0. fn: 175.0.\n",
            "0 :  {'precision': 0.8181818181818182, 'recall': 0.6982758620689655, 'micro-F1': 0.7534883720930233}\n",
            "tp: 83.0. fp: 11.0. fn: 70.0.\n",
            "1 :  {'precision': 0.8829787234042553, 'recall': 0.5424836601307189, 'micro-F1': 0.6720647773279352}\n",
            "tp: 73.0. fp: 19.0. fn: 66.0.\n",
            "2 :  {'precision': 0.7934782608695652, 'recall': 0.5251798561151079, 'micro-F1': 0.632034632034632}\n",
            "tp: 57.0. fp: 8.0. fn: 41.0.\n",
            "3 :  {'precision': 0.8769230769230769, 'recall': 0.5816326530612245, 'micro-F1': 0.6993865030674845}\n",
            "tp: 528.0. fp: 114.0. fn: 276.0.\n",
            "4 :  {'precision': 0.822429906542056, 'recall': 0.6567164179104478, 'micro-F1': 0.7302904564315352}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** aspect results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 73.03%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 82.24%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 65.67%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 348.0. fp: 149.0. fn: 248.0.\n",
            "0 :  {'precision': 0.7002012072434608, 'recall': 0.5838926174496645, 'micro-F1': 0.6367795059469351}\n",
            "tp: 71.0. fp: 23.0. fn: 89.0.\n",
            "1 :  {'precision': 0.7553191489361702, 'recall': 0.44375, 'micro-F1': 0.5590551181102362}\n",
            "tp: 64.0. fp: 28.0. fn: 80.0.\n",
            "2 :  {'precision': 0.6956521739130435, 'recall': 0.4444444444444444, 'micro-F1': 0.5423728813559322}\n",
            "tp: 51.0. fp: 14.0. fn: 52.0.\n",
            "3 :  {'precision': 0.7846153846153846, 'recall': 0.49514563106796117, 'micro-F1': 0.6071428571428571}\n",
            "tp: 456.0. fp: 188.0. fn: 371.0.\n",
            "4 :  {'precision': 0.7080745341614907, 'recall': 0.5513905683192262, 'micro-F1': 0.6199864038069341}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category aspect results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 62.00%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 70.81%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 55.14%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 379.0. fp: 125.0. fn: 210.0.\n",
            "0 :  {'precision': 0.751984126984127, 'recall': 0.6434634974533107, 'micro-F1': 0.6935041171088746}\n",
            "tp: 79.0. fp: 15.0. fn: 79.0.\n",
            "1 :  {'precision': 0.8404255319148937, 'recall': 0.5, 'micro-F1': 0.626984126984127}\n",
            "tp: 63.0. fp: 30.0. fn: 78.0.\n",
            "2 :  {'precision': 0.6774193548387096, 'recall': 0.44680851063829785, 'micro-F1': 0.5384615384615384}\n",
            "tp: 45.0. fp: 22.0. fn: 56.0.\n",
            "3 :  {'precision': 0.6716417910447762, 'recall': 0.44554455445544555, 'micro-F1': 0.5357142857142857}\n",
            "tp: 478.0. fp: 175.0. fn: 340.0.\n",
            "4 :  {'precision': 0.7320061255742726, 'recall': 0.5843520782396088, 'micro-F1': 0.6498980285520053}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** sentiment aspect results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 64.99%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 73.20%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 58.44%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 327.0. fp: 179.0. fn: 273.0.\n",
            "0 :  {'precision': 0.6462450592885376, 'recall': 0.545, 'micro-F1': 0.5913200723327307}\n",
            "tp: 68.0. fp: 26.0. fn: 93.0.\n",
            "1 :  {'precision': 0.723404255319149, 'recall': 0.422360248447205, 'micro-F1': 0.5333333333333333}\n",
            "tp: 56.0. fp: 37.0. fn: 89.0.\n",
            "2 :  {'precision': 0.6021505376344086, 'recall': 0.38620689655172413, 'micro-F1': 0.47058823529411764}\n",
            "tp: 42.0. fp: 25.0. fn: 61.0.\n",
            "3 :  {'precision': 0.6268656716417911, 'recall': 0.4077669902912621, 'micro-F1': 0.4941176470588235}\n",
            "tp: 417.0. fp: 238.0. fn: 415.0.\n",
            "4 :  {'precision': 0.6366412213740458, 'recall': 0.5012019230769231, 'micro-F1': 0.5608607935440485}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category sentiment aspect results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 56.09%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 63.66%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 50.12%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 426.0. fp: 83.0. fn: 154.0.\n",
            "0 :  {'precision': 0.8369351669941061, 'recall': 0.7344827586206897, 'micro-F1': 0.7823691460055097}\n",
            "tp: 77.0. fp: 18.0. fn: 73.0.\n",
            "1 :  {'precision': 0.8105263157894737, 'recall': 0.5133333333333333, 'micro-F1': 0.6285714285714286}\n",
            "tp: 57.0. fp: 20.0. fn: 56.0.\n",
            "2 :  {'precision': 0.7402597402597403, 'recall': 0.504424778761062, 'micro-F1': 0.6}\n",
            "tp: 55.0. fp: 8.0. fn: 47.0.\n",
            "3 :  {'precision': 0.873015873015873, 'recall': 0.5392156862745098, 'micro-F1': 0.6666666666666666}\n",
            "tp: 544.0. fp: 114.0. fn: 267.0.\n",
            "4 :  {'precision': 0.8267477203647416, 'recall': 0.6707768187422934, 'micro-F1': 0.740639891082369}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 74.06%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 82.67%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 67.08%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 357.0. fp: 204.0. fn: 238.0.\n",
            "0 :  {'precision': 0.6363636363636364, 'recall': 0.6, 'micro-F1': 0.6176470588235293}\n",
            "tp: 62.0. fp: 41.0. fn: 92.0.\n",
            "1 :  {'precision': 0.6019417475728155, 'recall': 0.4025974025974026, 'micro-F1': 0.48249027237354086}\n",
            "tp: 46.0. fp: 31.0. fn: 70.0.\n",
            "2 :  {'precision': 0.5974025974025974, 'recall': 0.39655172413793105, 'micro-F1': 0.4766839378238342}\n",
            "tp: 49.0. fp: 15.0. fn: 54.0.\n",
            "3 :  {'precision': 0.765625, 'recall': 0.47572815533980584, 'micro-F1': 0.5868263473053892}\n",
            "tp: 461.0. fp: 250.0. fn: 366.0.\n",
            "4 :  {'precision': 0.6483825597749648, 'recall': 0.5574365175332527, 'micro-F1': 0.599479843953186}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 59.95%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 64.84%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 55.74%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 397.0. fp: 121.0. fn: 183.0.\n",
            "0 :  {'precision': 0.7664092664092664, 'recall': 0.6844827586206896, 'micro-F1': 0.7231329690346084}\n",
            "tp: 70.0. fp: 25.0. fn: 80.0.\n",
            "1 :  {'precision': 0.7368421052631579, 'recall': 0.4666666666666667, 'micro-F1': 0.5714285714285714}\n",
            "tp: 48.0. fp: 30.0. fn: 66.0.\n",
            "2 :  {'precision': 0.6153846153846154, 'recall': 0.42105263157894735, 'micro-F1': 0.5}\n",
            "tp: 44.0. fp: 22.0. fn: 59.0.\n",
            "3 :  {'precision': 0.6666666666666666, 'recall': 0.42718446601941745, 'micro-F1': 0.5207100591715976}\n",
            "tp: 494.0. fp: 176.0. fn: 318.0.\n",
            "4 :  {'precision': 0.7373134328358208, 'recall': 0.6083743842364532, 'micro-F1': 0.6666666666666666}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** sentiment opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 66.67%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 73.73%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 60.84%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 337.0. fp: 233.0. fn: 258.0.\n",
            "0 :  {'precision': 0.5912280701754385, 'recall': 0.5663865546218487, 'micro-F1': 0.5785407725321888}\n",
            "tp: 59.0. fp: 44.0. fn: 95.0.\n",
            "1 :  {'precision': 0.5728155339805825, 'recall': 0.38311688311688313, 'micro-F1': 0.4591439688715953}\n",
            "tp: 39.0. fp: 39.0. fn: 78.0.\n",
            "2 :  {'precision': 0.5, 'recall': 0.3333333333333333, 'micro-F1': 0.4}\n",
            "tp: 41.0. fp: 25.0. fn: 63.0.\n",
            "3 :  {'precision': 0.6212121212121212, 'recall': 0.3942307692307692, 'micro-F1': 0.48235294117647054}\n",
            "tp: 425.0. fp: 297.0. fn: 403.0.\n",
            "4 :  {'precision': 0.5886426592797784, 'recall': 0.5132850241545893, 'micro-F1': 0.5483870967741935}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category sentiment opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 54.84%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 58.86%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 51.33%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 403.0. fp: 395.0. fn: 256.0.\n",
            "0 :  {'precision': 0.5050125313283208, 'recall': 0.6115326251896813, 'micro-F1': 0.5531914893617021}\n",
            "tp: 74.0. fp: 55.0. fn: 93.0.\n",
            "1 :  {'precision': 0.5736434108527132, 'recall': 0.4431137724550898, 'micro-F1': 0.5}\n",
            "tp: 50.0. fp: 87.0. fn: 97.0.\n",
            "2 :  {'precision': 0.36496350364963503, 'recall': 0.3401360544217687, 'micro-F1': 0.35211267605633806}\n",
            "tp: 53.0. fp: 16.0. fn: 51.0.\n",
            "3 :  {'precision': 0.7681159420289855, 'recall': 0.5096153846153846, 'micro-F1': 0.6127167630057804}\n",
            "tp: 508.0. fp: 454.0. fn: 387.0.\n",
            "4 :  {'precision': 0.5280665280665281, 'recall': 0.5675977653631284, 'micro-F1': 0.5471190091545504}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** aspect opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 54.71%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 52.81%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 56.76%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 354.0. fp: 446.0. fn: 305.0.\n",
            "0 :  {'precision': 0.4425, 'recall': 0.5371775417298937, 'micro-F1': 0.4852638793694311}\n",
            "tp: 66.0. fp: 63.0. fn: 101.0.\n",
            "1 :  {'precision': 0.5116279069767442, 'recall': 0.39520958083832336, 'micro-F1': 0.44594594594594594}\n",
            "tp: 44.0. fp: 93.0. fn: 103.0.\n",
            "2 :  {'precision': 0.32116788321167883, 'recall': 0.29931972789115646, 'micro-F1': 0.3098591549295775}\n",
            "tp: 48.0. fp: 21.0. fn: 56.0.\n",
            "3 :  {'precision': 0.6956521739130435, 'recall': 0.46153846153846156, 'micro-F1': 0.5549132947976878}\n",
            "tp: 449.0. fp: 515.0. fn: 446.0.\n",
            "4 :  {'precision': 0.4657676348547718, 'recall': 0.5016759776536313, 'micro-F1': 0.4830554061323292}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category aspect opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 48.31%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 46.58%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 50.17%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 381.0. fp: 426.0. fn: 278.0.\n",
            "0 :  {'precision': 0.4721189591078067, 'recall': 0.5781487101669196, 'micro-F1': 0.5197817189631652}\n",
            "tp: 71.0. fp: 58.0. fn: 96.0.\n",
            "1 :  {'precision': 0.5503875968992248, 'recall': 0.4251497005988024, 'micro-F1': 0.47972972972972977}\n",
            "tp: 44.0. fp: 94.0. fn: 103.0.\n",
            "2 :  {'precision': 0.3188405797101449, 'recall': 0.29931972789115646, 'micro-F1': 0.3087719298245614}\n",
            "tp: 42.0. fp: 29.0. fn: 62.0.\n",
            "3 :  {'precision': 0.5915492957746479, 'recall': 0.40384615384615385, 'micro-F1': 0.48000000000000004}\n",
            "tp: 468.0. fp: 505.0. fn: 427.0.\n",
            "4 :  {'precision': 0.48098663926002055, 'recall': 0.5229050279329609, 'micro-F1': 0.5010706638115633}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** sentiment aspect opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 50.11%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 48.10%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 52.29%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "tp: 337.0. fp: 472.0. fn: 322.0.\n",
            "0 :  {'precision': 0.41656365883807167, 'recall': 0.511380880121396, 'micro-F1': 0.4591280653950954}\n",
            "tp: 63.0. fp: 66.0. fn: 104.0.\n",
            "1 :  {'precision': 0.4883720930232558, 'recall': 0.3772455089820359, 'micro-F1': 0.42567567567567566}\n",
            "tp: 39.0. fp: 99.0. fn: 108.0.\n",
            "2 :  {'precision': 0.2826086956521739, 'recall': 0.2653061224489796, 'micro-F1': 0.2736842105263158}\n",
            "tp: 40.0. fp: 31.0. fn: 64.0.\n",
            "3 :  {'precision': 0.5633802816901409, 'recall': 0.38461538461538464, 'micro-F1': 0.4571428571428572}\n",
            "tp: 418.0. fp: 557.0. fn: 477.0.\n",
            "4 :  {'precision': 0.4287179487179487, 'recall': 0.4670391061452514, 'micro-F1': 0.4470588235294118}\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   ***** category sentiment aspect opinion results *****\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     micro-F1 = 44.71%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     precision = 42.87%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -     recall = 46.70%\n",
            "06/07/2022 10:16:23 - INFO - __main__ -   -----------------------------------\n",
            "06/07/2022 10:16:24 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:16:24 - INFO - __main__ -     micro-F1 = 0.4470588235294118\n",
            "06/07/2022 10:16:24 - INFO - __main__ -     precision = 0.4287179487179487\n",
            "06/07/2022 10:16:24 - INFO - __main__ -     recall = 0.4670391061452514\n",
            "Epoch:  30% 3/10 [02:13<05:14, 44.86s/it]06/07/2022 10:16:24 - INFO - __main__ -   Total Loss is 0.027647698298096657 .\n",
            "06/07/2022 10:16:26 - INFO - __main__ -   Total Loss is 0.02290511131286621 .\n",
            "06/07/2022 10:16:29 - INFO - __main__ -   Total Loss is 0.0465632900595665 .\n",
            "06/07/2022 10:16:32 - INFO - __main__ -   Total Loss is 0.0228273905813694 .\n",
            "06/07/2022 10:16:34 - INFO - __main__ -   Total Loss is 0.03873434662818909 .\n",
            "06/07/2022 10:16:37 - INFO - __main__ -   Total Loss is 0.03771812096238136 .\n",
            "06/07/2022 10:16:39 - INFO - __main__ -   Total Loss is 0.0313304103910923 .\n",
            "06/07/2022 10:16:42 - INFO - __main__ -   Total Loss is 0.03571908921003342 .\n",
            "06/07/2022 10:16:44 - INFO - __main__ -   Total Loss is 0.027990978211164474 .\n",
            "06/07/2022 10:16:47 - INFO - __main__ -   Total Loss is 0.031083684414625168 .\n",
            "06/07/2022 10:16:49 - INFO - __main__ -   Total Loss is 0.015840720385313034 .\n",
            "06/07/2022 10:16:52 - INFO - __main__ -   Total Loss is 0.046536825597286224 .\n",
            "06/07/2022 10:16:54 - INFO - __main__ -   Total Loss is 0.03834911063313484 .\n",
            "06/07/2022 10:16:56 - INFO - __main__ -   Total Loss is 0.027064405381679535 .\n",
            "06/07/2022 10:16:59 - INFO - __main__ -   Total Loss is 0.030720338225364685 .\n",
            "06/07/2022 10:17:01 - INFO - __main__ -   Total Loss is 0.03874848037958145 .\n",
            "Quad num: 192\n",
            "tp: 144.0. fp: 48.0. fn: 107.0.\n",
            "06/07/2022 10:17:02 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:17:02 - INFO - __main__ -     micro-F1 = 0.6501128668171559\n",
            "06/07/2022 10:17:02 - INFO - __main__ -     precision = 0.75\n",
            "06/07/2022 10:17:02 - INFO - __main__ -     recall = 0.5737051792828686\n",
            "Quad num: 917\n",
            "tp: 409.0. fp: 508.0. fn: 486.0.\n",
            "tp: 319.0. fp: 51.0. fn: 171.0.\n",
            "0 :  {'precision': 0.8621621621621621, 'recall': 0.6510204081632653, 'micro-F1': 0.7418604651162792}\n",
            "tp: 62.0. fp: 17.0. fn: 80.0.\n",
            "1 :  {'precision': 0.7848101265822784, 'recall': 0.43661971830985913, 'micro-F1': 0.5610859728506786}\n",
            "tp: 54.0. fp: 14.0. fn: 44.0.\n",
            "2 :  {'precision': 0.7941176470588235, 'recall': 0.5510204081632653, 'micro-F1': 0.6506024096385542}\n",
            "tp: 50.0. fp: 10.0. fn: 52.0.\n",
            "3 :  {'precision': 0.8333333333333334, 'recall': 0.49019607843137253, 'micro-F1': 0.6172839506172839}\n",
            "tp: 433.0. fp: 86.0. fn: 282.0.\n",
            "4 :  {'precision': 0.8342967244701349, 'recall': 0.6055944055944056, 'micro-F1': 0.7017828200972447}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 70.18%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 83.43%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 60.56%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 306.0. fp: 28.0. fn: 93.0.\n",
            "0 :  {'precision': 0.9161676646706587, 'recall': 0.7669172932330827, 'micro-F1': 0.834924965893588}\n",
            "tp: 68.0. fp: 5.0. fn: 55.0.\n",
            "1 :  {'precision': 0.9315068493150684, 'recall': 0.5528455284552846, 'micro-F1': 0.693877551020408}\n",
            "tp: 53.0. fp: 13.0. fn: 32.0.\n",
            "2 :  {'precision': 0.803030303030303, 'recall': 0.6235294117647059, 'micro-F1': 0.7019867549668874}\n",
            "tp: 47.0. fp: 13.0. fn: 48.0.\n",
            "3 :  {'precision': 0.7833333333333333, 'recall': 0.49473684210526314, 'micro-F1': 0.6064516129032258}\n",
            "tp: 425.0. fp: 56.0. fn: 198.0.\n",
            "4 :  {'precision': 0.8835758835758836, 'recall': 0.6821829855537721, 'micro-F1': 0.769927536231884}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** sentiment results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 76.99%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 88.36%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 68.22%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 294.0. fp: 81.0. fn: 203.0.\n",
            "0 :  {'precision': 0.784, 'recall': 0.5915492957746479, 'micro-F1': 0.6743119266055047}\n",
            "tp: 58.0. fp: 21.0. fn: 86.0.\n",
            "1 :  {'precision': 0.7341772151898734, 'recall': 0.4027777777777778, 'micro-F1': 0.5201793721973095}\n",
            "tp: 45.0. fp: 24.0. fn: 56.0.\n",
            "2 :  {'precision': 0.6521739130434783, 'recall': 0.44554455445544555, 'micro-F1': 0.5294117647058824}\n",
            "tp: 42.0. fp: 18.0. fn: 61.0.\n",
            "3 :  {'precision': 0.7, 'recall': 0.4077669902912621, 'micro-F1': 0.5153374233128835}\n",
            "tp: 390.0. fp: 134.0. fn: 335.0.\n",
            "4 :  {'precision': 0.7442748091603053, 'recall': 0.5379310344827586, 'micro-F1': 0.6244995996797438}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category sentiment results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 62.45%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 74.43%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 53.79%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 393.0. fp: 85.0. fn: 187.0.\n",
            "0 :  {'precision': 0.8221757322175732, 'recall': 0.6775862068965517, 'micro-F1': 0.7429111531190926}\n",
            "tp: 89.0. fp: 9.0. fn: 64.0.\n",
            "1 :  {'precision': 0.9081632653061225, 'recall': 0.5816993464052288, 'micro-F1': 0.7091633466135457}\n",
            "tp: 76.0. fp: 22.0. fn: 63.0.\n",
            "2 :  {'precision': 0.7755102040816326, 'recall': 0.5467625899280576, 'micro-F1': 0.6413502109704641}\n",
            "tp: 59.0. fp: 4.0. fn: 39.0.\n",
            "3 :  {'precision': 0.9365079365079365, 'recall': 0.6020408163265306, 'micro-F1': 0.732919254658385}\n",
            "tp: 528.0. fp: 111.0. fn: 276.0.\n",
            "4 :  {'precision': 0.8262910798122066, 'recall': 0.6567164179104478, 'micro-F1': 0.7318087318087318}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** aspect results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 73.18%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 82.63%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 65.67%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 343.0. fp: 141.0. fn: 253.0.\n",
            "0 :  {'precision': 0.7086776859504132, 'recall': 0.575503355704698, 'micro-F1': 0.6351851851851852}\n",
            "tp: 70.0. fp: 28.0. fn: 90.0.\n",
            "1 :  {'precision': 0.7142857142857143, 'recall': 0.4375, 'micro-F1': 0.5426356589147286}\n",
            "tp: 67.0. fp: 32.0. fn: 77.0.\n",
            "2 :  {'precision': 0.6767676767676768, 'recall': 0.4652777777777778, 'micro-F1': 0.551440329218107}\n",
            "tp: 49.0. fp: 14.0. fn: 54.0.\n",
            "3 :  {'precision': 0.7777777777777778, 'recall': 0.47572815533980584, 'micro-F1': 0.5903614457831325}\n",
            "tp: 451.0. fp: 195.0. fn: 376.0.\n",
            "4 :  {'precision': 0.6981424148606811, 'recall': 0.5453446191051995, 'micro-F1': 0.6123557365919892}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category aspect results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 61.24%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 69.81%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 54.53%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 364.0. fp: 118.0. fn: 225.0.\n",
            "0 :  {'precision': 0.7551867219917012, 'recall': 0.6179966044142614, 'micro-F1': 0.6797385620915032}\n",
            "tp: 83.0. fp: 15.0. fn: 75.0.\n",
            "1 :  {'precision': 0.8469387755102041, 'recall': 0.5253164556962026, 'micro-F1': 0.6484375000000001}\n",
            "tp: 65.0. fp: 34.0. fn: 76.0.\n",
            "2 :  {'precision': 0.6565656565656566, 'recall': 0.46099290780141844, 'micro-F1': 0.5416666666666666}\n",
            "tp: 44.0. fp: 19.0. fn: 57.0.\n",
            "3 :  {'precision': 0.6984126984126984, 'recall': 0.43564356435643564, 'micro-F1': 0.5365853658536586}\n",
            "tp: 473.0. fp: 170.0. fn: 345.0.\n",
            "4 :  {'precision': 0.7356143079315708, 'recall': 0.578239608801956, 'micro-F1': 0.6475017111567419}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** sentiment aspect results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 64.75%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 73.56%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 57.82%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 318.0. fp: 169.0. fn: 282.0.\n",
            "0 :  {'precision': 0.6529774127310062, 'recall': 0.53, 'micro-F1': 0.5850965961361546}\n",
            "tp: 66.0. fp: 32.0. fn: 95.0.\n",
            "1 :  {'precision': 0.673469387755102, 'recall': 0.40993788819875776, 'micro-F1': 0.5096525096525096}\n",
            "tp: 57.0. fp: 43.0. fn: 88.0.\n",
            "2 :  {'precision': 0.57, 'recall': 0.3931034482758621, 'micro-F1': 0.46530612244897956}\n",
            "tp: 40.0. fp: 23.0. fn: 63.0.\n",
            "3 :  {'precision': 0.6349206349206349, 'recall': 0.3883495145631068, 'micro-F1': 0.48192771084337344}\n",
            "tp: 408.0. fp: 241.0. fn: 424.0.\n",
            "4 :  {'precision': 0.6286594761171033, 'recall': 0.49038461538461536, 'micro-F1': 0.5509790681971641}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category sentiment aspect results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 55.10%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 62.87%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 49.04%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 415.0. fp: 72.0. fn: 165.0.\n",
            "0 :  {'precision': 0.8521560574948666, 'recall': 0.7155172413793104, 'micro-F1': 0.7778819119025304}\n",
            "tp: 81.0. fp: 16.0. fn: 69.0.\n",
            "1 :  {'precision': 0.8350515463917526, 'recall': 0.54, 'micro-F1': 0.6558704453441295}\n",
            "tp: 62.0. fp: 13.0. fn: 51.0.\n",
            "2 :  {'precision': 0.8266666666666667, 'recall': 0.5486725663716814, 'micro-F1': 0.6595744680851063}\n",
            "tp: 55.0. fp: 9.0. fn: 47.0.\n",
            "3 :  {'precision': 0.859375, 'recall': 0.5392156862745098, 'micro-F1': 0.6626506024096386}\n",
            "tp: 544.0. fp: 101.0. fn: 267.0.\n",
            "4 :  {'precision': 0.8434108527131783, 'recall': 0.6707768187422934, 'micro-F1': 0.7472527472527472}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 74.73%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 84.34%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 67.08%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 350.0. fp: 186.0. fn: 245.0.\n",
            "0 :  {'precision': 0.6529850746268657, 'recall': 0.5882352941176471, 'micro-F1': 0.618921308576481}\n",
            "tp: 60.0. fp: 45.0. fn: 94.0.\n",
            "1 :  {'precision': 0.5714285714285714, 'recall': 0.38961038961038963, 'micro-F1': 0.46332046332046334}\n",
            "tp: 50.0. fp: 28.0. fn: 66.0.\n",
            "2 :  {'precision': 0.6410256410256411, 'recall': 0.43103448275862066, 'micro-F1': 0.5154639175257731}\n",
            "tp: 47.0. fp: 17.0. fn: 56.0.\n",
            "3 :  {'precision': 0.734375, 'recall': 0.4563106796116505, 'micro-F1': 0.562874251497006}\n",
            "tp: 454.0. fp: 242.0. fn: 373.0.\n",
            "4 :  {'precision': 0.6522988505747126, 'recall': 0.5489721886336155, 'micro-F1': 0.5961917268548916}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 59.62%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 65.23%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 54.90%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 388.0. fp: 100.0. fn: 192.0.\n",
            "0 :  {'precision': 0.7950819672131147, 'recall': 0.6689655172413793, 'micro-F1': 0.7265917602996254}\n",
            "tp: 75.0. fp: 22.0. fn: 75.0.\n",
            "1 :  {'precision': 0.7731958762886598, 'recall': 0.5, 'micro-F1': 0.6072874493927126}\n",
            "tp: 52.0. fp: 23.0. fn: 62.0.\n",
            "2 :  {'precision': 0.6933333333333334, 'recall': 0.45614035087719296, 'micro-F1': 0.5502645502645502}\n",
            "tp: 43.0. fp: 21.0. fn: 60.0.\n",
            "3 :  {'precision': 0.671875, 'recall': 0.4174757281553398, 'micro-F1': 0.5149700598802395}\n",
            "tp: 495.0. fp: 151.0. fn: 317.0.\n",
            "4 :  {'precision': 0.7662538699690402, 'recall': 0.6096059113300493, 'micro-F1': 0.6790123456790123}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** sentiment opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 67.90%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 76.63%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 60.96%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 328.0. fp: 209.0. fn: 267.0.\n",
            "0 :  {'precision': 0.6108007448789572, 'recall': 0.5512605042016807, 'micro-F1': 0.5795053003533569}\n",
            "tp: 57.0. fp: 48.0. fn: 97.0.\n",
            "1 :  {'precision': 0.5428571428571428, 'recall': 0.37012987012987014, 'micro-F1': 0.44015444015444016}\n",
            "tp: 43.0. fp: 35.0. fn: 74.0.\n",
            "2 :  {'precision': 0.5512820512820513, 'recall': 0.36752136752136755, 'micro-F1': 0.44102564102564107}\n",
            "tp: 40.0. fp: 24.0. fn: 64.0.\n",
            "3 :  {'precision': 0.625, 'recall': 0.38461538461538464, 'micro-F1': 0.4761904761904762}\n",
            "tp: 418.0. fp: 279.0. fn: 410.0.\n",
            "4 :  {'precision': 0.599713055954089, 'recall': 0.5048309178743962, 'micro-F1': 0.5481967213114755}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category sentiment opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 54.82%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 59.97%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 50.48%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 388.0. fp: 347.0. fn: 271.0.\n",
            "0 :  {'precision': 0.527891156462585, 'recall': 0.5887708649468892, 'micro-F1': 0.5566714490674318}\n",
            "tp: 81.0. fp: 51.0. fn: 86.0.\n",
            "1 :  {'precision': 0.6136363636363636, 'recall': 0.48502994011976047, 'micro-F1': 0.5418060200668896}\n",
            "tp: 55.0. fp: 78.0. fn: 92.0.\n",
            "2 :  {'precision': 0.41353383458646614, 'recall': 0.3741496598639456, 'micro-F1': 0.39285714285714285}\n",
            "tp: 54.0. fp: 13.0. fn: 50.0.\n",
            "3 :  {'precision': 0.8059701492537313, 'recall': 0.5192307692307693, 'micro-F1': 0.6315789473684211}\n",
            "tp: 504.0. fp: 407.0. fn: 391.0.\n",
            "4 :  {'precision': 0.5532381997804611, 'recall': 0.5631284916201117, 'micro-F1': 0.5581395348837209}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** aspect opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 55.81%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 55.32%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 56.31%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 345.0. fp: 394.0. fn: 314.0.\n",
            "0 :  {'precision': 0.4668470906630582, 'recall': 0.5235204855842185, 'micro-F1': 0.49356223175965663}\n",
            "tp: 67.0. fp: 65.0. fn: 100.0.\n",
            "1 :  {'precision': 0.5075757575757576, 'recall': 0.40119760479041916, 'micro-F1': 0.4481605351170569}\n",
            "tp: 48.0. fp: 86.0. fn: 99.0.\n",
            "2 :  {'precision': 0.3582089552238806, 'recall': 0.32653061224489793, 'micro-F1': 0.3416370106761566}\n",
            "tp: 46.0. fp: 21.0. fn: 58.0.\n",
            "3 :  {'precision': 0.6865671641791045, 'recall': 0.4423076923076923, 'micro-F1': 0.5380116959064327}\n",
            "tp: 441.0. fp: 475.0. fn: 454.0.\n",
            "4 :  {'precision': 0.4814410480349345, 'recall': 0.49273743016759775, 'micro-F1': 0.4870237437879624}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category aspect opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 48.70%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 48.14%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 49.27%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 367.0. fp: 369.0. fn: 292.0.\n",
            "0 :  {'precision': 0.4986413043478261, 'recall': 0.5569044006069803, 'micro-F1': 0.5261648745519714}\n",
            "tp: 78.0. fp: 54.0. fn: 89.0.\n",
            "1 :  {'precision': 0.5909090909090909, 'recall': 0.46706586826347307, 'micro-F1': 0.5217391304347826}\n",
            "tp: 48.0. fp: 85.0. fn: 99.0.\n",
            "2 :  {'precision': 0.3609022556390977, 'recall': 0.32653061224489793, 'micro-F1': 0.34285714285714286}\n",
            "tp: 41.0. fp: 26.0. fn: 63.0.\n",
            "3 :  {'precision': 0.6119402985074627, 'recall': 0.3942307692307692, 'micro-F1': 0.4795321637426901}\n",
            "tp: 464.0. fp: 448.0. fn: 431.0.\n",
            "4 :  {'precision': 0.5087719298245614, 'recall': 0.5184357541899441, 'micro-F1': 0.5135583840619812}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** sentiment aspect opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 51.36%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 50.88%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 51.84%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "tp: 326.0. fp: 414.0. fn: 333.0.\n",
            "0 :  {'precision': 0.44054054054054054, 'recall': 0.4946889226100152, 'micro-F1': 0.4660471765546819}\n",
            "tp: 64.0. fp: 68.0. fn: 103.0.\n",
            "1 :  {'precision': 0.48484848484848486, 'recall': 0.38323353293413176, 'micro-F1': 0.4280936454849499}\n",
            "tp: 42.0. fp: 92.0. fn: 105.0.\n",
            "2 :  {'precision': 0.31343283582089554, 'recall': 0.2857142857142857, 'micro-F1': 0.298932384341637}\n",
            "tp: 38.0. fp: 29.0. fn: 66.0.\n",
            "3 :  {'precision': 0.5671641791044776, 'recall': 0.36538461538461536, 'micro-F1': 0.4444444444444444}\n",
            "tp: 409.0. fp: 508.0. fn: 486.0.\n",
            "4 :  {'precision': 0.44601962922573607, 'recall': 0.4569832402234637, 'micro-F1': 0.45143487858719644}\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   ***** category sentiment aspect opinion results *****\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     micro-F1 = 45.14%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     precision = 44.60%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -     recall = 45.70%\n",
            "06/07/2022 10:17:08 - INFO - __main__ -   -----------------------------------\n",
            "06/07/2022 10:17:09 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:17:09 - INFO - __main__ -     micro-F1 = 0.45143487858719644\n",
            "06/07/2022 10:17:09 - INFO - __main__ -     precision = 0.44601962922573607\n",
            "06/07/2022 10:17:09 - INFO - __main__ -     recall = 0.4569832402234637\n",
            "Epoch:  40% 4/10 [02:58<04:29, 44.96s/it]06/07/2022 10:17:09 - INFO - __main__ -   Total Loss is 0.017149725928902626 .\n",
            "06/07/2022 10:17:11 - INFO - __main__ -   Total Loss is 0.02605896070599556 .\n",
            "06/07/2022 10:17:14 - INFO - __main__ -   Total Loss is 0.024743955582380295 .\n",
            "06/07/2022 10:17:17 - INFO - __main__ -   Total Loss is 0.025391245260834694 .\n",
            "06/07/2022 10:17:19 - INFO - __main__ -   Total Loss is 0.015748286619782448 .\n",
            "06/07/2022 10:17:22 - INFO - __main__ -   Total Loss is 0.022007955238223076 .\n",
            "06/07/2022 10:17:24 - INFO - __main__ -   Total Loss is 0.022944273427128792 .\n",
            "06/07/2022 10:17:27 - INFO - __main__ -   Total Loss is 0.011726772412657738 .\n",
            "06/07/2022 10:17:29 - INFO - __main__ -   Total Loss is 0.020922202616930008 .\n",
            "06/07/2022 10:17:32 - INFO - __main__ -   Total Loss is 0.01394259836524725 .\n",
            "06/07/2022 10:17:34 - INFO - __main__ -   Total Loss is 0.019648011773824692 .\n",
            "06/07/2022 10:17:37 - INFO - __main__ -   Total Loss is 0.023870276287198067 .\n",
            "06/07/2022 10:17:39 - INFO - __main__ -   Total Loss is 0.019548680633306503 .\n",
            "06/07/2022 10:17:42 - INFO - __main__ -   Total Loss is 0.03230145201086998 .\n",
            "06/07/2022 10:17:44 - INFO - __main__ -   Total Loss is 0.030628805980086327 .\n",
            "06/07/2022 10:17:47 - INFO - __main__ -   Total Loss is 0.022975429892539978 .\n",
            "Quad num: 206\n",
            "tp: 149.0. fp: 57.0. fn: 102.0.\n",
            "06/07/2022 10:17:48 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:17:48 - INFO - __main__ -     micro-F1 = 0.6520787746170679\n",
            "06/07/2022 10:17:48 - INFO - __main__ -     precision = 0.7233009708737864\n",
            "06/07/2022 10:17:48 - INFO - __main__ -     recall = 0.5936254980079682\n",
            "Quad num: 1058\n",
            "tp: 457.0. fp: 601.0. fn: 438.0.\n",
            "tp: 358.0. fp: 55.0. fn: 132.0.\n",
            "0 :  {'precision': 0.8668280871670703, 'recall': 0.7306122448979592, 'micro-F1': 0.7929125138427464}\n",
            "tp: 79.0. fp: 21.0. fn: 63.0.\n",
            "1 :  {'precision': 0.79, 'recall': 0.5563380281690141, 'micro-F1': 0.6528925619834711}\n",
            "tp: 58.0. fp: 10.0. fn: 40.0.\n",
            "2 :  {'precision': 0.8529411764705882, 'recall': 0.5918367346938775, 'micro-F1': 0.6987951807228915}\n",
            "tp: 58.0. fp: 10.0. fn: 44.0.\n",
            "3 :  {'precision': 0.8529411764705882, 'recall': 0.5686274509803921, 'micro-F1': 0.6823529411764706}\n",
            "tp: 491.0. fp: 92.0. fn: 224.0.\n",
            "4 :  {'precision': 0.8421955403087479, 'recall': 0.6867132867132867, 'micro-F1': 0.7565485362095531}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 75.65%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 84.22%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 68.67%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 326.0. fp: 33.0. fn: 73.0.\n",
            "0 :  {'precision': 0.9080779944289693, 'recall': 0.8170426065162907, 'micro-F1': 0.8601583113456464}\n",
            "tp: 80.0. fp: 10.0. fn: 43.0.\n",
            "1 :  {'precision': 0.8888888888888888, 'recall': 0.6504065040650406, 'micro-F1': 0.7511737089201878}\n",
            "tp: 51.0. fp: 15.0. fn: 34.0.\n",
            "2 :  {'precision': 0.7727272727272727, 'recall': 0.6, 'micro-F1': 0.6754966887417219}\n",
            "tp: 56.0. fp: 12.0. fn: 39.0.\n",
            "3 :  {'precision': 0.8235294117647058, 'recall': 0.5894736842105263, 'micro-F1': 0.6871165644171779}\n",
            "tp: 462.0. fp: 66.0. fn: 161.0.\n",
            "4 :  {'precision': 0.875, 'recall': 0.7415730337078652, 'micro-F1': 0.8027801911381407}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** sentiment results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 80.28%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 87.50%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 74.16%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 329.0. fp: 89.0. fn: 168.0.\n",
            "0 :  {'precision': 0.7870813397129187, 'recall': 0.6619718309859155, 'micro-F1': 0.7191256830601094}\n",
            "tp: 70.0. fp: 30.0. fn: 74.0.\n",
            "1 :  {'precision': 0.7, 'recall': 0.4861111111111111, 'micro-F1': 0.5737704918032787}\n",
            "tp: 47.0. fp: 22.0. fn: 54.0.\n",
            "2 :  {'precision': 0.6811594202898551, 'recall': 0.46534653465346537, 'micro-F1': 0.5529411764705882}\n",
            "tp: 50.0. fp: 18.0. fn: 53.0.\n",
            "3 :  {'precision': 0.7352941176470589, 'recall': 0.4854368932038835, 'micro-F1': 0.5847953216374269}\n",
            "tp: 440.0. fp: 149.0. fn: 285.0.\n",
            "4 :  {'precision': 0.7470288624787776, 'recall': 0.6068965517241379, 'micro-F1': 0.669710806697108}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category sentiment results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 66.97%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 74.70%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 60.69%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 428.0. fp: 96.0. fn: 152.0.\n",
            "0 :  {'precision': 0.816793893129771, 'recall': 0.7379310344827587, 'micro-F1': 0.7753623188405797}\n",
            "tp: 106.0. fp: 12.0. fn: 47.0.\n",
            "1 :  {'precision': 0.8983050847457628, 'recall': 0.6928104575163399, 'micro-F1': 0.7822878228782287}\n",
            "tp: 78.0. fp: 22.0. fn: 61.0.\n",
            "2 :  {'precision': 0.78, 'recall': 0.5611510791366906, 'micro-F1': 0.6527196652719666}\n",
            "tp: 66.0. fp: 8.0. fn: 32.0.\n",
            "3 :  {'precision': 0.8918918918918919, 'recall': 0.673469387755102, 'micro-F1': 0.7674418604651163}\n",
            "tp: 581.0. fp: 124.0. fn: 223.0.\n",
            "4 :  {'precision': 0.8241134751773049, 'recall': 0.722636815920398, 'micro-F1': 0.7700463883366468}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** aspect results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 77.00%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 82.41%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 72.26%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 380.0. fp: 170.0. fn: 216.0.\n",
            "0 :  {'precision': 0.6909090909090909, 'recall': 0.6375838926174496, 'micro-F1': 0.6631762652705061}\n",
            "tp: 87.0. fp: 34.0. fn: 73.0.\n",
            "1 :  {'precision': 0.71900826446281, 'recall': 0.54375, 'micro-F1': 0.6192170818505338}\n",
            "tp: 69.0. fp: 31.0. fn: 75.0.\n",
            "2 :  {'precision': 0.69, 'recall': 0.4791666666666667, 'micro-F1': 0.5655737704918032}\n",
            "tp: 57.0. fp: 17.0. fn: 46.0.\n",
            "3 :  {'precision': 0.7702702702702703, 'recall': 0.5533980582524272, 'micro-F1': 0.6440677966101694}\n",
            "tp: 506.0. fp: 227.0. fn: 321.0.\n",
            "4 :  {'precision': 0.6903137789904502, 'recall': 0.6118500604594922, 'micro-F1': 0.6487179487179487}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category aspect results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 64.87%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 69.03%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 61.19%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 400.0. fp: 132.0. fn: 189.0.\n",
            "0 :  {'precision': 0.7518796992481203, 'recall': 0.6791171477079796, 'micro-F1': 0.7136485280999108}\n",
            "tp: 95.0. fp: 23.0. fn: 63.0.\n",
            "1 :  {'precision': 0.8050847457627118, 'recall': 0.6012658227848101, 'micro-F1': 0.6884057971014492}\n",
            "tp: 69.0. fp: 32.0. fn: 72.0.\n",
            "2 :  {'precision': 0.6831683168316832, 'recall': 0.48936170212765956, 'micro-F1': 0.5702479338842975}\n",
            "tp: 54.0. fp: 20.0. fn: 47.0.\n",
            "3 :  {'precision': 0.7297297297297297, 'recall': 0.5346534653465347, 'micro-F1': 0.6171428571428571}\n",
            "tp: 526.0. fp: 188.0. fn: 292.0.\n",
            "4 :  {'precision': 0.7366946778711485, 'recall': 0.6430317848410758, 'micro-F1': 0.6866840731070496}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** sentiment aspect results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 68.67%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 73.67%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 64.30%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 354.0. fp: 202.0. fn: 246.0.\n",
            "0 :  {'precision': 0.6366906474820144, 'recall': 0.59, 'micro-F1': 0.6124567474048443}\n",
            "tp: 78.0. fp: 43.0. fn: 83.0.\n",
            "1 :  {'precision': 0.6446280991735537, 'recall': 0.484472049689441, 'micro-F1': 0.5531914893617021}\n",
            "tp: 61.0. fp: 40.0. fn: 84.0.\n",
            "2 :  {'precision': 0.6039603960396039, 'recall': 0.4206896551724138, 'micro-F1': 0.4959349593495934}\n",
            "tp: 49.0. fp: 25.0. fn: 54.0.\n",
            "3 :  {'precision': 0.6621621621621622, 'recall': 0.47572815533980584, 'micro-F1': 0.5536723163841809}\n",
            "tp: 460.0. fp: 280.0. fn: 372.0.\n",
            "4 :  {'precision': 0.6216216216216216, 'recall': 0.5528846153846154, 'micro-F1': 0.5852417302798982}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category sentiment aspect results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 58.52%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 62.16%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 55.29%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 446.0. fp: 88.0. fn: 134.0.\n",
            "0 :  {'precision': 0.8352059925093633, 'recall': 0.7689655172413793, 'micro-F1': 0.8007181328545782}\n",
            "tp: 93.0. fp: 24.0. fn: 57.0.\n",
            "1 :  {'precision': 0.7948717948717948, 'recall': 0.62, 'micro-F1': 0.6966292134831461}\n",
            "tp: 62.0. fp: 17.0. fn: 51.0.\n",
            "2 :  {'precision': 0.7848101265822784, 'recall': 0.5486725663716814, 'micro-F1': 0.6458333333333334}\n",
            "tp: 64.0. fp: 12.0. fn: 38.0.\n",
            "3 :  {'precision': 0.8421052631578947, 'recall': 0.6274509803921569, 'micro-F1': 0.7191011235955056}\n",
            "tp: 593.0. fp: 128.0. fn: 218.0.\n",
            "4 :  {'precision': 0.8224687933425797, 'recall': 0.7311960542540074, 'micro-F1': 0.7741514360313315}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 77.42%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 82.25%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 73.12%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 391.0. fp: 218.0. fn: 204.0.\n",
            "0 :  {'precision': 0.6420361247947455, 'recall': 0.6571428571428571, 'micro-F1': 0.649501661129568}\n",
            "tp: 73.0. fp: 55.0. fn: 81.0.\n",
            "1 :  {'precision': 0.5703125, 'recall': 0.474025974025974, 'micro-F1': 0.5177304964539007}\n",
            "tp: 50.0. fp: 32.0. fn: 66.0.\n",
            "2 :  {'precision': 0.6097560975609756, 'recall': 0.43103448275862066, 'micro-F1': 0.5050505050505051}\n",
            "tp: 54.0. fp: 22.0. fn: 49.0.\n",
            "3 :  {'precision': 0.7105263157894737, 'recall': 0.5242718446601942, 'micro-F1': 0.6033519553072626}\n",
            "tp: 510.0. fp: 287.0. fn: 317.0.\n",
            "4 :  {'precision': 0.6398996235884568, 'recall': 0.6166868198307134, 'micro-F1': 0.6280788177339901}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 62.81%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 63.99%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 61.67%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 418.0. fp: 122.0. fn: 162.0.\n",
            "0 :  {'precision': 0.774074074074074, 'recall': 0.7206896551724138, 'micro-F1': 0.7464285714285714}\n",
            "tp: 83.0. fp: 34.0. fn: 67.0.\n",
            "1 :  {'precision': 0.7094017094017094, 'recall': 0.5533333333333333, 'micro-F1': 0.6217228464419476}\n",
            "tp: 50.0. fp: 31.0. fn: 64.0.\n",
            "2 :  {'precision': 0.6172839506172839, 'recall': 0.43859649122807015, 'micro-F1': 0.5128205128205128}\n",
            "tp: 53.0. fp: 23.0. fn: 50.0.\n",
            "3 :  {'precision': 0.6973684210526315, 'recall': 0.5145631067961165, 'micro-F1': 0.5921787709497206}\n",
            "tp: 539.0. fp: 189.0. fn: 273.0.\n",
            "4 :  {'precision': 0.7403846153846154, 'recall': 0.6637931034482759, 'micro-F1': 0.7000000000000001}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** sentiment opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 70.00%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 74.04%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 66.38%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 366.0. fp: 248.0. fn: 229.0.\n",
            "0 :  {'precision': 0.5960912052117264, 'recall': 0.6151260504201681, 'micro-F1': 0.6054590570719603}\n",
            "tp: 66.0. fp: 62.0. fn: 88.0.\n",
            "1 :  {'precision': 0.515625, 'recall': 0.42857142857142855, 'micro-F1': 0.4680851063829787}\n",
            "tp: 42.0. fp: 41.0. fn: 75.0.\n",
            "2 :  {'precision': 0.5060240963855421, 'recall': 0.358974358974359, 'micro-F1': 0.42000000000000004}\n",
            "tp: 47.0. fp: 29.0. fn: 57.0.\n",
            "3 :  {'precision': 0.618421052631579, 'recall': 0.4519230769230769, 'micro-F1': 0.5222222222222223}\n",
            "tp: 468.0. fp: 335.0. fn: 360.0.\n",
            "4 :  {'precision': 0.5828144458281445, 'recall': 0.5652173913043478, 'micro-F1': 0.5738810545677498}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category sentiment opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 57.39%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 58.28%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 56.52%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 429.0. fp: 407.0. fn: 230.0.\n",
            "0 :  {'precision': 0.5131578947368421, 'recall': 0.6509863429438544, 'micro-F1': 0.573913043478261}\n",
            "tp: 93.0. fp: 63.0. fn: 74.0.\n",
            "1 :  {'precision': 0.5961538461538461, 'recall': 0.5568862275449101, 'micro-F1': 0.5758513931888544}\n",
            "tp: 55.0. fp: 84.0. fn: 92.0.\n",
            "2 :  {'precision': 0.39568345323741005, 'recall': 0.3741496598639456, 'micro-F1': 0.38461538461538464}\n",
            "tp: 61.0. fp: 21.0. fn: 43.0.\n",
            "3 :  {'precision': 0.7439024390243902, 'recall': 0.5865384615384616, 'micro-F1': 0.6559139784946237}\n",
            "tp: 560.0. fp: 479.0. fn: 335.0.\n",
            "4 :  {'precision': 0.5389797882579404, 'recall': 0.6256983240223464, 'micro-F1': 0.5791106514994829}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** aspect opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 57.91%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 53.90%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 62.57%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 384.0. fp: 464.0. fn: 275.0.\n",
            "0 :  {'precision': 0.4528301886792453, 'recall': 0.582701062215478, 'micro-F1': 0.5096217650962176}\n",
            "tp: 80.0. fp: 77.0. fn: 87.0.\n",
            "1 :  {'precision': 0.5095541401273885, 'recall': 0.47904191616766467, 'micro-F1': 0.4938271604938272}\n",
            "tp: 47.0. fp: 92.0. fn: 100.0.\n",
            "2 :  {'precision': 0.3381294964028777, 'recall': 0.3197278911564626, 'micro-F1': 0.3286713286713287}\n",
            "tp: 53.0. fp: 29.0. fn: 51.0.\n",
            "3 :  {'precision': 0.6463414634146342, 'recall': 0.5096153846153846, 'micro-F1': 0.5698924731182795}\n",
            "tp: 494.0. fp: 558.0. fn: 401.0.\n",
            "4 :  {'precision': 0.4695817490494297, 'recall': 0.5519553072625698, 'micro-F1': 0.507447354904982}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category aspect opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 50.74%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 46.96%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 55.20%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 404.0. fp: 437.0. fn: 255.0.\n",
            "0 :  {'precision': 0.4803804994054697, 'recall': 0.6130500758725341, 'micro-F1': 0.5386666666666666}\n",
            "tp: 85.0. fp: 71.0. fn: 82.0.\n",
            "1 :  {'precision': 0.5448717948717948, 'recall': 0.5089820359281437, 'micro-F1': 0.5263157894736842}\n",
            "tp: 49.0. fp: 91.0. fn: 98.0.\n",
            "2 :  {'precision': 0.35, 'recall': 0.3333333333333333, 'micro-F1': 0.3414634146341463}\n",
            "tp: 50.0. fp: 32.0. fn: 54.0.\n",
            "3 :  {'precision': 0.6097560975609756, 'recall': 0.4807692307692308, 'micro-F1': 0.5376344086021505}\n",
            "tp: 515.0. fp: 530.0. fn: 380.0.\n",
            "4 :  {'precision': 0.49282296650717705, 'recall': 0.5754189944134078, 'micro-F1': 0.5309278350515464}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** sentiment aspect opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 53.09%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 49.28%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 57.54%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "tp: 361.0. fp: 492.0. fn: 298.0.\n",
            "0 :  {'precision': 0.4232121922626026, 'recall': 0.5477996965098634, 'micro-F1': 0.4775132275132275}\n",
            "tp: 73.0. fp: 84.0. fn: 94.0.\n",
            "1 :  {'precision': 0.46496815286624205, 'recall': 0.437125748502994, 'micro-F1': 0.4506172839506173}\n",
            "tp: 42.0. fp: 98.0. fn: 105.0.\n",
            "2 :  {'precision': 0.3, 'recall': 0.2857142857142857, 'micro-F1': 0.2926829268292683}\n",
            "tp: 46.0. fp: 36.0. fn: 58.0.\n",
            "3 :  {'precision': 0.5609756097560976, 'recall': 0.4423076923076923, 'micro-F1': 0.4946236559139785}\n",
            "tp: 457.0. fp: 601.0. fn: 438.0.\n",
            "4 :  {'precision': 0.43194706994328924, 'recall': 0.5106145251396648, 'micro-F1': 0.4679979518689196}\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** category sentiment aspect opinion results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 46.80%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 43.19%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 51.06%\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   -----------------------------------\n",
            "06/07/2022 10:17:54 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     micro-F1 = 0.4679979518689196\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     precision = 0.43194706994328924\n",
            "06/07/2022 10:17:54 - INFO - __main__ -     recall = 0.5106145251396648\n",
            "Epoch:  50% 5/10 [03:44<03:45, 45.07s/it]06/07/2022 10:17:54 - INFO - __main__ -   Total Loss is 0.014143574051558971 .\n",
            "06/07/2022 10:17:57 - INFO - __main__ -   Total Loss is 0.019228532910346985 .\n",
            "06/07/2022 10:17:59 - INFO - __main__ -   Total Loss is 0.01449535507708788 .\n",
            "06/07/2022 10:18:02 - INFO - __main__ -   Total Loss is 0.018970634788274765 .\n",
            "06/07/2022 10:18:05 - INFO - __main__ -   Total Loss is 0.02030712552368641 .\n",
            "06/07/2022 10:18:07 - INFO - __main__ -   Total Loss is 0.010587124153971672 .\n",
            "06/07/2022 10:18:10 - INFO - __main__ -   Total Loss is 0.007348938845098019 .\n",
            "06/07/2022 10:18:12 - INFO - __main__ -   Total Loss is 0.015396622940897942 .\n",
            "06/07/2022 10:18:15 - INFO - __main__ -   Total Loss is 0.020540611818432808 .\n",
            "06/07/2022 10:18:17 - INFO - __main__ -   Total Loss is 0.015107371844351292 .\n",
            "06/07/2022 10:18:20 - INFO - __main__ -   Total Loss is 0.01886671409010887 .\n",
            "06/07/2022 10:18:22 - INFO - __main__ -   Total Loss is 0.021103130653500557 .\n",
            "06/07/2022 10:18:25 - INFO - __main__ -   Total Loss is 0.0365026630461216 .\n",
            "06/07/2022 10:18:27 - INFO - __main__ -   Total Loss is 0.009423308074474335 .\n",
            "06/07/2022 10:18:30 - INFO - __main__ -   Total Loss is 0.00963761005550623 .\n",
            "06/07/2022 10:18:32 - INFO - __main__ -   Total Loss is 0.014449408277869225 .\n",
            "Quad num: 213\n",
            "tp: 157.0. fp: 56.0. fn: 94.0.\n",
            "06/07/2022 10:18:33 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:18:33 - INFO - __main__ -     micro-F1 = 0.6767241379310345\n",
            "06/07/2022 10:18:33 - INFO - __main__ -     precision = 0.7370892018779343\n",
            "06/07/2022 10:18:33 - INFO - __main__ -     recall = 0.6254980079681275\n",
            "Quad num: 1043\n",
            "tp: 475.0. fp: 568.0. fn: 420.0.\n",
            "tp: 367.0. fp: 52.0. fn: 123.0.\n",
            "0 :  {'precision': 0.8758949880668258, 'recall': 0.7489795918367347, 'micro-F1': 0.8074807480748074}\n",
            "tp: 86.0. fp: 22.0. fn: 56.0.\n",
            "1 :  {'precision': 0.7962962962962963, 'recall': 0.6056338028169014, 'micro-F1': 0.688}\n",
            "tp: 61.0. fp: 10.0. fn: 37.0.\n",
            "2 :  {'precision': 0.8591549295774648, 'recall': 0.6224489795918368, 'micro-F1': 0.7218934911242604}\n",
            "tp: 62.0. fp: 10.0. fn: 40.0.\n",
            "3 :  {'precision': 0.8611111111111112, 'recall': 0.6078431372549019, 'micro-F1': 0.7126436781609194}\n",
            "tp: 509.0. fp: 88.0. fn: 206.0.\n",
            "4 :  {'precision': 0.8525963149078727, 'recall': 0.7118881118881119, 'micro-F1': 0.7759146341463414}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 77.59%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 85.26%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 71.19%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 334.0. fp: 30.0. fn: 65.0.\n",
            "0 :  {'precision': 0.9175824175824175, 'recall': 0.8370927318295739, 'micro-F1': 0.8754914809960681}\n",
            "tp: 86.0. fp: 11.0. fn: 37.0.\n",
            "1 :  {'precision': 0.8865979381443299, 'recall': 0.6991869918699187, 'micro-F1': 0.7818181818181819}\n",
            "tp: 56.0. fp: 11.0. fn: 29.0.\n",
            "2 :  {'precision': 0.835820895522388, 'recall': 0.6588235294117647, 'micro-F1': 0.7368421052631579}\n",
            "tp: 59.0. fp: 13.0. fn: 36.0.\n",
            "3 :  {'precision': 0.8194444444444444, 'recall': 0.6210526315789474, 'micro-F1': 0.7065868263473054}\n",
            "tp: 478.0. fp: 63.0. fn: 145.0.\n",
            "4 :  {'precision': 0.8835489833641405, 'recall': 0.7672552166934189, 'micro-F1': 0.8213058419243985}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** sentiment results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 82.13%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 88.35%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 76.73%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 344.0. fp: 84.0. fn: 153.0.\n",
            "0 :  {'precision': 0.8037383177570093, 'recall': 0.6921529175050302, 'micro-F1': 0.7437837837837837}\n",
            "tp: 76.0. fp: 32.0. fn: 68.0.\n",
            "1 :  {'precision': 0.7037037037037037, 'recall': 0.5277777777777778, 'micro-F1': 0.6031746031746033}\n",
            "tp: 52.0. fp: 20.0. fn: 49.0.\n",
            "2 :  {'precision': 0.7222222222222222, 'recall': 0.5148514851485149, 'micro-F1': 0.6011560693641618}\n",
            "tp: 53.0. fp: 19.0. fn: 50.0.\n",
            "3 :  {'precision': 0.7361111111111112, 'recall': 0.5145631067961165, 'micro-F1': 0.6057142857142858}\n",
            "tp: 462.0. fp: 144.0. fn: 263.0.\n",
            "4 :  {'precision': 0.7623762376237624, 'recall': 0.6372413793103449, 'micro-F1': 0.6942148760330579}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category sentiment results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 69.42%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 76.24%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 63.72%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 430.0. fp: 93.0. fn: 150.0.\n",
            "0 :  {'precision': 0.8221797323135756, 'recall': 0.7413793103448276, 'micro-F1': 0.7796917497733454}\n",
            "tp: 114.0. fp: 11.0. fn: 39.0.\n",
            "1 :  {'precision': 0.912, 'recall': 0.7450980392156863, 'micro-F1': 0.8201438848920864}\n",
            "tp: 81.0. fp: 20.0. fn: 58.0.\n",
            "2 :  {'precision': 0.801980198019802, 'recall': 0.5827338129496403, 'micro-F1': 0.675}\n",
            "tp: 71.0. fp: 5.0. fn: 27.0.\n",
            "3 :  {'precision': 0.9342105263157895, 'recall': 0.7244897959183674, 'micro-F1': 0.8160919540229886}\n",
            "tp: 594.0. fp: 117.0. fn: 210.0.\n",
            "4 :  {'precision': 0.8354430379746836, 'recall': 0.7388059701492538, 'micro-F1': 0.7841584158415843}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** aspect results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 78.42%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 83.54%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 73.88%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 393.0. fp: 156.0. fn: 203.0.\n",
            "0 :  {'precision': 0.7158469945355191, 'recall': 0.6593959731543624, 'micro-F1': 0.6864628820960698}\n",
            "tp: 96.0. fp: 33.0. fn: 64.0.\n",
            "1 :  {'precision': 0.7441860465116279, 'recall': 0.6, 'micro-F1': 0.6643598615916955}\n",
            "tp: 71.0. fp: 30.0. fn: 73.0.\n",
            "2 :  {'precision': 0.7029702970297029, 'recall': 0.4930555555555556, 'micro-F1': 0.5795918367346938}\n",
            "tp: 61.0. fp: 15.0. fn: 42.0.\n",
            "3 :  {'precision': 0.8026315789473685, 'recall': 0.5922330097087378, 'micro-F1': 0.6815642458100559}\n",
            "tp: 527.0. fp: 211.0. fn: 300.0.\n",
            "4 :  {'precision': 0.7140921409214093, 'recall': 0.6372430471584039, 'micro-F1': 0.6734824281150159}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category aspect results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 67.35%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 71.41%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 63.72%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 400.0. fp: 133.0. fn: 189.0.\n",
            "0 :  {'precision': 0.7504690431519699, 'recall': 0.6791171477079796, 'micro-F1': 0.71301247771836}\n",
            "tp: 102.0. fp: 23.0. fn: 56.0.\n",
            "1 :  {'precision': 0.816, 'recall': 0.6455696202531646, 'micro-F1': 0.7208480565371025}\n",
            "tp: 73.0. fp: 29.0. fn: 68.0.\n",
            "2 :  {'precision': 0.7156862745098039, 'recall': 0.5177304964539007, 'micro-F1': 0.6008230452674898}\n",
            "tp: 57.0. fp: 19.0. fn: 44.0.\n",
            "3 :  {'precision': 0.75, 'recall': 0.5643564356435643, 'micro-F1': 0.6440677966101693}\n",
            "tp: 534.0. fp: 187.0. fn: 284.0.\n",
            "4 :  {'precision': 0.7406380027739251, 'recall': 0.6528117359413202, 'micro-F1': 0.6939571150097466}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** sentiment aspect results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 69.40%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 74.06%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 65.28%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 368.0. fp: 190.0. fn: 232.0.\n",
            "0 :  {'precision': 0.6594982078853047, 'recall': 0.6133333333333333, 'micro-F1': 0.6355785837651122}\n",
            "tp: 86.0. fp: 43.0. fn: 75.0.\n",
            "1 :  {'precision': 0.6666666666666666, 'recall': 0.5341614906832298, 'micro-F1': 0.593103448275862}\n",
            "tp: 64.0. fp: 38.0. fn: 81.0.\n",
            "2 :  {'precision': 0.6274509803921569, 'recall': 0.4413793103448276, 'micro-F1': 0.5182186234817814}\n",
            "tp: 52.0. fp: 24.0. fn: 51.0.\n",
            "3 :  {'precision': 0.6842105263157895, 'recall': 0.5048543689320388, 'micro-F1': 0.5810055865921787}\n",
            "tp: 480.0. fp: 267.0. fn: 352.0.\n",
            "4 :  {'precision': 0.642570281124498, 'recall': 0.5769230769230769, 'micro-F1': 0.6079797340088664}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category sentiment aspect results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 60.80%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 64.26%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 57.69%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 449.0. fp: 85.0. fn: 131.0.\n",
            "0 :  {'precision': 0.8408239700374532, 'recall': 0.7741379310344828, 'micro-F1': 0.8061041292639138}\n",
            "tp: 101.0. fp: 25.0. fn: 49.0.\n",
            "1 :  {'precision': 0.8015873015873016, 'recall': 0.6733333333333333, 'micro-F1': 0.7318840579710145}\n",
            "tp: 62.0. fp: 18.0. fn: 51.0.\n",
            "2 :  {'precision': 0.775, 'recall': 0.5486725663716814, 'micro-F1': 0.6424870466321244}\n",
            "tp: 67.0. fp: 10.0. fn: 35.0.\n",
            "3 :  {'precision': 0.8701298701298701, 'recall': 0.6568627450980392, 'micro-F1': 0.7486033519553071}\n",
            "tp: 605.0. fp: 125.0. fn: 206.0.\n",
            "4 :  {'precision': 0.8287671232876712, 'recall': 0.7459926017262639, 'micro-F1': 0.7852044127190136}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 78.52%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 82.88%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 74.60%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 403.0. fp: 205.0. fn: 192.0.\n",
            "0 :  {'precision': 0.662828947368421, 'recall': 0.6773109243697479, 'micro-F1': 0.6699916874480465}\n",
            "tp: 80.0. fp: 58.0. fn: 74.0.\n",
            "1 :  {'precision': 0.5797101449275363, 'recall': 0.5194805194805194, 'micro-F1': 0.5479452054794519}\n",
            "tp: 52.0. fp: 34.0. fn: 64.0.\n",
            "2 :  {'precision': 0.6046511627906976, 'recall': 0.4482758620689655, 'micro-F1': 0.5148514851485148}\n",
            "tp: 58.0. fp: 19.0. fn: 45.0.\n",
            "3 :  {'precision': 0.7532467532467533, 'recall': 0.5631067961165048, 'micro-F1': 0.6444444444444444}\n",
            "tp: 530.0. fp: 275.0. fn: 297.0.\n",
            "4 :  {'precision': 0.6583850931677019, 'recall': 0.6408706166868199, 'micro-F1': 0.6495098039215687}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 64.95%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 65.84%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 64.09%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 422.0. fp: 118.0. fn: 158.0.\n",
            "0 :  {'precision': 0.7814814814814814, 'recall': 0.7275862068965517, 'micro-F1': 0.7535714285714284}\n",
            "tp: 88.0. fp: 39.0. fn: 62.0.\n",
            "1 :  {'precision': 0.6929133858267716, 'recall': 0.5866666666666667, 'micro-F1': 0.6353790613718412}\n",
            "tp: 52.0. fp: 29.0. fn: 62.0.\n",
            "2 :  {'precision': 0.6419753086419753, 'recall': 0.45614035087719296, 'micro-F1': 0.5333333333333333}\n",
            "tp: 53.0. fp: 24.0. fn: 50.0.\n",
            "3 :  {'precision': 0.6883116883116883, 'recall': 0.5145631067961165, 'micro-F1': 0.5888888888888889}\n",
            "tp: 548.0. fp: 188.0. fn: 264.0.\n",
            "4 :  {'precision': 0.7445652173913043, 'recall': 0.6748768472906403, 'micro-F1': 0.7080103359173125}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** sentiment opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 70.80%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 74.46%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 67.49%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 380.0. fp: 232.0. fn: 215.0.\n",
            "0 :  {'precision': 0.6209150326797386, 'recall': 0.6386554621848739, 'micro-F1': 0.6296603148301574}\n",
            "tp: 70.0. fp: 68.0. fn: 84.0.\n",
            "1 :  {'precision': 0.5072463768115942, 'recall': 0.45454545454545453, 'micro-F1': 0.4794520547945206}\n",
            "tp: 45.0. fp: 41.0. fn: 72.0.\n",
            "2 :  {'precision': 0.5232558139534884, 'recall': 0.38461538461538464, 'micro-F1': 0.4433497536945813}\n",
            "tp: 50.0. fp: 27.0. fn: 54.0.\n",
            "3 :  {'precision': 0.6493506493506493, 'recall': 0.4807692307692308, 'micro-F1': 0.5524861878453039}\n",
            "tp: 486.0. fp: 323.0. fn: 342.0.\n",
            "4 :  {'precision': 0.6007416563658838, 'recall': 0.5869565217391305, 'micro-F1': 0.5937690897984117}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category sentiment opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 59.38%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 60.07%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 58.70%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 430.0. fp: 393.0. fn: 229.0.\n",
            "0 :  {'precision': 0.5224787363304981, 'recall': 0.6525037936267072, 'micro-F1': 0.5802968960863698}\n",
            "tp: 104.0. fp: 62.0. fn: 63.0.\n",
            "1 :  {'precision': 0.6265060240963856, 'recall': 0.6227544910179641, 'micro-F1': 0.6246246246246246}\n",
            "tp: 56.0. fp: 84.0. fn: 91.0.\n",
            "2 :  {'precision': 0.4, 'recall': 0.38095238095238093, 'micro-F1': 0.3902439024390244}\n",
            "tp: 66.0. fp: 15.0. fn: 38.0.\n",
            "3 :  {'precision': 0.8148148148148148, 'recall': 0.6346153846153846, 'micro-F1': 0.7135135135135134}\n",
            "tp: 572.0. fp: 461.0. fn: 323.0.\n",
            "4 :  {'precision': 0.5537270087124879, 'recall': 0.6391061452513966, 'micro-F1': 0.5933609958506224}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** aspect opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 59.34%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 55.37%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 63.91%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 396.0. fp: 434.0. fn: 263.0.\n",
            "0 :  {'precision': 0.4771084337349398, 'recall': 0.6009104704097117, 'micro-F1': 0.531900604432505}\n",
            "tp: 89.0. fp: 78.0. fn: 78.0.\n",
            "1 :  {'precision': 0.5329341317365269, 'recall': 0.5329341317365269, 'micro-F1': 0.5329341317365269}\n",
            "tp: 49.0. fp: 91.0. fn: 98.0.\n",
            "2 :  {'precision': 0.35, 'recall': 0.3333333333333333, 'micro-F1': 0.3414634146341463}\n",
            "tp: 57.0. fp: 24.0. fn: 47.0.\n",
            "3 :  {'precision': 0.7037037037037037, 'recall': 0.5480769230769231, 'micro-F1': 0.6162162162162163}\n",
            "tp: 514.0. fp: 527.0. fn: 381.0.\n",
            "4 :  {'precision': 0.49375600384245916, 'recall': 0.5743016759776536, 'micro-F1': 0.53099173553719}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category aspect opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 53.10%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 49.38%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 57.43%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 406.0. fp: 419.0. fn: 253.0.\n",
            "0 :  {'precision': 0.4921212121212121, 'recall': 0.6160849772382397, 'micro-F1': 0.5471698113207547}\n",
            "tp: 93.0. fp: 73.0. fn: 74.0.\n",
            "1 :  {'precision': 0.5602409638554217, 'recall': 0.5568862275449101, 'micro-F1': 0.5585585585585585}\n",
            "tp: 51.0. fp: 89.0. fn: 96.0.\n",
            "2 :  {'precision': 0.36428571428571427, 'recall': 0.3469387755102041, 'micro-F1': 0.3554006968641115}\n",
            "tp: 52.0. fp: 29.0. fn: 52.0.\n",
            "3 :  {'precision': 0.6419753086419753, 'recall': 0.5, 'micro-F1': 0.5621621621621622}\n",
            "tp: 523.0. fp: 512.0. fn: 372.0.\n",
            "4 :  {'precision': 0.5053140096618357, 'recall': 0.5843575418994413, 'micro-F1': 0.5419689119170983}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** sentiment aspect opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 54.20%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 50.53%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 58.44%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "tp: 375.0. fp: 457.0. fn: 284.0.\n",
            "0 :  {'precision': 0.45072115384615385, 'recall': 0.5690440060698028, 'micro-F1': 0.5030181086519115}\n",
            "tp: 79.0. fp: 88.0. fn: 88.0.\n",
            "1 :  {'precision': 0.47305389221556887, 'recall': 0.47305389221556887, 'micro-F1': 0.47305389221556887}\n",
            "tp: 45.0. fp: 95.0. fn: 102.0.\n",
            "2 :  {'precision': 0.32142857142857145, 'recall': 0.30612244897959184, 'micro-F1': 0.313588850174216}\n",
            "tp: 49.0. fp: 32.0. fn: 55.0.\n",
            "3 :  {'precision': 0.6049382716049383, 'recall': 0.47115384615384615, 'micro-F1': 0.5297297297297296}\n",
            "tp: 475.0. fp: 568.0. fn: 420.0.\n",
            "4 :  {'precision': 0.4554170661553212, 'recall': 0.5307262569832403, 'micro-F1': 0.4901960784313726}\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** category sentiment aspect opinion results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 49.02%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 45.54%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 53.07%\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   -----------------------------------\n",
            "06/07/2022 10:18:40 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     micro-F1 = 0.4901960784313726\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     precision = 0.4554170661553212\n",
            "06/07/2022 10:18:40 - INFO - __main__ -     recall = 0.5307262569832403\n",
            "Epoch:  60% 6/10 [04:30<03:01, 45.38s/it]06/07/2022 10:18:40 - INFO - __main__ -   Total Loss is 0.009857210330665112 .\n",
            "06/07/2022 10:18:43 - INFO - __main__ -   Total Loss is 0.01695367507636547 .\n",
            "06/07/2022 10:18:45 - INFO - __main__ -   Total Loss is 0.007549252361059189 .\n",
            "06/07/2022 10:18:48 - INFO - __main__ -   Total Loss is 0.0172293521463871 .\n",
            "06/07/2022 10:18:51 - INFO - __main__ -   Total Loss is 0.01045105792582035 .\n",
            "06/07/2022 10:18:53 - INFO - __main__ -   Total Loss is 0.019396357238292694 .\n",
            "06/07/2022 10:18:55 - INFO - __main__ -   Total Loss is 0.023347964510321617 .\n",
            "06/07/2022 10:18:58 - INFO - __main__ -   Total Loss is 0.012876703403890133 .\n",
            "06/07/2022 10:19:00 - INFO - __main__ -   Total Loss is 0.023430289700627327 .\n",
            "06/07/2022 10:19:03 - INFO - __main__ -   Total Loss is 0.008790325373411179 .\n",
            "06/07/2022 10:19:06 - INFO - __main__ -   Total Loss is 0.013393576256930828 .\n",
            "06/07/2022 10:19:08 - INFO - __main__ -   Total Loss is 0.020978856831789017 .\n",
            "06/07/2022 10:19:11 - INFO - __main__ -   Total Loss is 0.013835567981004715 .\n",
            "06/07/2022 10:19:14 - INFO - __main__ -   Total Loss is 0.011639895848929882 .\n",
            "06/07/2022 10:19:16 - INFO - __main__ -   Total Loss is 0.007129991892725229 .\n",
            "06/07/2022 10:19:18 - INFO - __main__ -   Total Loss is 0.02490200102329254 .\n",
            "Quad num: 209\n",
            "tp: 155.0. fp: 54.0. fn: 96.0.\n",
            "06/07/2022 10:19:20 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:19:20 - INFO - __main__ -     micro-F1 = 0.6739130434782609\n",
            "06/07/2022 10:19:20 - INFO - __main__ -     precision = 0.7416267942583732\n",
            "06/07/2022 10:19:20 - INFO - __main__ -     recall = 0.6175298804780877\n",
            "Epoch:  70% 7/10 [05:09<02:10, 43.47s/it]06/07/2022 10:19:20 - INFO - __main__ -   Total Loss is 0.010773224756121635 .\n",
            "06/07/2022 10:19:22 - INFO - __main__ -   Total Loss is 0.016301365569233894 .\n",
            "06/07/2022 10:19:24 - INFO - __main__ -   Total Loss is 0.011591305956244469 .\n",
            "06/07/2022 10:19:27 - INFO - __main__ -   Total Loss is 0.01165907271206379 .\n",
            "06/07/2022 10:19:29 - INFO - __main__ -   Total Loss is 0.006124373059719801 .\n",
            "06/07/2022 10:19:32 - INFO - __main__ -   Total Loss is 0.015091043896973133 .\n",
            "06/07/2022 10:19:34 - INFO - __main__ -   Total Loss is 0.009422756731510162 .\n",
            "06/07/2022 10:19:37 - INFO - __main__ -   Total Loss is 0.010716304183006287 .\n",
            "06/07/2022 10:19:39 - INFO - __main__ -   Total Loss is 0.007171040400862694 .\n",
            "06/07/2022 10:19:42 - INFO - __main__ -   Total Loss is 0.007215315010398626 .\n",
            "06/07/2022 10:19:44 - INFO - __main__ -   Total Loss is 0.015385126695036888 .\n",
            "06/07/2022 10:19:46 - INFO - __main__ -   Total Loss is 0.006203194614499807 .\n",
            "06/07/2022 10:19:49 - INFO - __main__ -   Total Loss is 0.027232235297560692 .\n",
            "06/07/2022 10:19:52 - INFO - __main__ -   Total Loss is 0.00703844428062439 .\n",
            "06/07/2022 10:19:54 - INFO - __main__ -   Total Loss is 0.013636085204780102 .\n",
            "06/07/2022 10:19:57 - INFO - __main__ -   Total Loss is 0.011585711501538754 .\n",
            "Quad num: 212\n",
            "tp: 156.0. fp: 56.0. fn: 95.0.\n",
            "06/07/2022 10:19:58 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:19:58 - INFO - __main__ -     micro-F1 = 0.673866090712743\n",
            "06/07/2022 10:19:58 - INFO - __main__ -     precision = 0.7358490566037735\n",
            "06/07/2022 10:19:58 - INFO - __main__ -     recall = 0.6215139442231076\n",
            "Epoch:  80% 8/10 [05:48<01:23, 41.86s/it]06/07/2022 10:19:58 - INFO - __main__ -   Total Loss is 0.009172771126031876 .\n",
            "06/07/2022 10:20:00 - INFO - __main__ -   Total Loss is 0.0037681669928133488 .\n",
            "06/07/2022 10:20:03 - INFO - __main__ -   Total Loss is 0.008824457414448261 .\n",
            "06/07/2022 10:20:05 - INFO - __main__ -   Total Loss is 0.01960066519677639 .\n",
            "06/07/2022 10:20:08 - INFO - __main__ -   Total Loss is 0.006405712570995092 .\n",
            "06/07/2022 10:20:10 - INFO - __main__ -   Total Loss is 0.01583760790526867 .\n",
            "06/07/2022 10:20:13 - INFO - __main__ -   Total Loss is 0.003409366123378277 .\n",
            "06/07/2022 10:20:15 - INFO - __main__ -   Total Loss is 0.012589854188263416 .\n",
            "06/07/2022 10:20:18 - INFO - __main__ -   Total Loss is 0.008661903440952301 .\n",
            "06/07/2022 10:20:21 - INFO - __main__ -   Total Loss is 0.008771835826337337 .\n",
            "06/07/2022 10:20:23 - INFO - __main__ -   Total Loss is 0.00807981751859188 .\n",
            "06/07/2022 10:20:25 - INFO - __main__ -   Total Loss is 0.004867029841989279 .\n",
            "06/07/2022 10:20:28 - INFO - __main__ -   Total Loss is 0.006094813346862793 .\n",
            "06/07/2022 10:20:31 - INFO - __main__ -   Total Loss is 0.0054376875050365925 .\n",
            "06/07/2022 10:20:33 - INFO - __main__ -   Total Loss is 0.004887829069048166 .\n",
            "06/07/2022 10:20:35 - INFO - __main__ -   Total Loss is 0.01659899577498436 .\n",
            "Quad num: 211\n",
            "tp: 153.0. fp: 58.0. fn: 98.0.\n",
            "06/07/2022 10:20:36 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:20:36 - INFO - __main__ -     micro-F1 = 0.6623376623376623\n",
            "06/07/2022 10:20:36 - INFO - __main__ -     precision = 0.7251184834123223\n",
            "06/07/2022 10:20:36 - INFO - __main__ -     recall = 0.6095617529880478\n",
            "Epoch:  90% 9/10 [06:26<00:40, 40.81s/it]06/07/2022 10:20:36 - INFO - __main__ -   Total Loss is 0.01118953712284565 .\n",
            "06/07/2022 10:20:39 - INFO - __main__ -   Total Loss is 0.007450080011039972 .\n",
            "06/07/2022 10:20:42 - INFO - __main__ -   Total Loss is 0.007553970441222191 .\n",
            "06/07/2022 10:20:44 - INFO - __main__ -   Total Loss is 0.005333263427019119 .\n",
            "06/07/2022 10:20:47 - INFO - __main__ -   Total Loss is 0.013458111323416233 .\n",
            "06/07/2022 10:20:49 - INFO - __main__ -   Total Loss is 0.009889421053230762 .\n",
            "06/07/2022 10:20:52 - INFO - __main__ -   Total Loss is 0.009336057119071484 .\n",
            "06/07/2022 10:20:54 - INFO - __main__ -   Total Loss is 0.009312568232417107 .\n",
            "06/07/2022 10:20:57 - INFO - __main__ -   Total Loss is 0.012815004214644432 .\n",
            "06/07/2022 10:20:59 - INFO - __main__ -   Total Loss is 0.012886829674243927 .\n",
            "06/07/2022 10:21:02 - INFO - __main__ -   Total Loss is 0.006548814941197634 .\n",
            "06/07/2022 10:21:04 - INFO - __main__ -   Total Loss is 0.00867293868213892 .\n",
            "06/07/2022 10:21:07 - INFO - __main__ -   Total Loss is 0.004750770516693592 .\n",
            "06/07/2022 10:21:09 - INFO - __main__ -   Total Loss is 0.0082596056163311 .\n",
            "06/07/2022 10:21:11 - INFO - __main__ -   Total Loss is 0.005172358360141516 .\n",
            "06/07/2022 10:21:14 - INFO - __main__ -   Total Loss is 0.004828897304832935 .\n",
            "Quad num: 204\n",
            "tp: 152.0. fp: 52.0. fn: 99.0.\n",
            "06/07/2022 10:21:15 - INFO - __main__ -   ***** Eval results *****\n",
            "06/07/2022 10:21:15 - INFO - __main__ -     micro-F1 = 0.6681318681318682\n",
            "06/07/2022 10:21:15 - INFO - __main__ -     precision = 0.7450980392156863\n",
            "06/07/2022 10:21:15 - INFO - __main__ -     recall = 0.6055776892430279\n",
            "Epoch: 100% 10/10 [07:05<00:00, 42.50s/it]\n",
            "06/07/2022 10:21:15 - INFO - __main__ -   ***** Test results *****\n",
            "06/07/2022 10:21:15 - INFO - __main__ -     micro-F1 = 0.4901960784313726\n",
            "06/07/2022 10:21:15 - INFO - __main__ -     precision = 0.4554170661553212\n",
            "06/07/2022 10:21:15 - INFO - __main__ -     recall = 0.5307262569832403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evYqfzpiXiQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}