{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydmou/ABSA/blob/main/ACOS_Crotrasive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yghILndFvE7d",
        "outputId": "28758122-2bbc-40b7-85a1-000adf14579a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n"
          ]
        }
      ],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihs2CdEAvLL3",
        "outputId": "14fb9b84-c304-4331-c99b-307087e074f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 26 12:38:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3HwFe8wvRd6",
        "outputId": "a2fc7026-16e9-4068-e6d5-376a25c3d038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.19.0\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.19.0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.0)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.12.1 transformers-4.19.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers==4.19.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GNj6DVTTvXhz"
      },
      "outputs": [],
      "source": [
        "!pip install torch>=1.10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YPvtZOKvus2",
        "outputId": "f6000fb2-f851-4990-ba11-1ce7df64aec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning==1.8.6\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (2023.4.0)\n",
            "Collecting tensorboardX>=2.2 (from pytorch_lightning==1.8.6)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics>=0.7.0 (from pytorch_lightning==1.8.6)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (4.5.0)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch_lightning==1.8.6)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (2.27.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch_lightning==1.8.6)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.2->pytorch_lightning==1.8.6) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->pytorch_lightning==1.8.6) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->pytorch_lightning==1.8.6) (16.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->pytorch_lightning==1.8.6) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->pytorch_lightning==1.8.6) (1.3.0)\n",
            "Installing collected packages: tensorboardX, multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch_lightning==1.8.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzu7OXc2v1JN"
      },
      "outputs": [],
      "source": [
        "pip install sentencepiece==0.1.97"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft9IGfa4v9-E"
      },
      "outputs": [],
      "source": [
        "import numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amiEPxLlwLIT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEBYPHXzwPKA",
        "outputId": "56a6271d-d505-4064-dbfe-b5bd17f87088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/ABSA-QUAD-master\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/ColabNotebooks/ABSA-QUAD-master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-b4q6hDwWYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3915de-4ca5-4086-bc1c-e68e7544df75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=1.10.0'   \u001b[0m\u001b[01;34mdrive\u001b[0m/   \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mK_FgmAwYyw"
      },
      "outputs": [],
      "source": [
        "!sh run.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDfFqOYHxSQ5",
        "outputId": "fd159434-e6f1-4259-ee30-01964383c443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: parse\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24570 sha256=31e3c42b56763ab4194ef92c0cffaa7f9988781f86a290522e13b4fccedcc6e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4b/f0/eaf5a8de646d8676dc25caa01949b9f9d883b8fa2efb435bc3\n",
            "Successfully built parse\n",
            "Installing collected packages: parse\n",
            "Successfully installed parse-1.19.0\n"
          ]
        }
      ],
      "source": [
        "pip install parse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-alkMJtJxDRj",
        "outputId": "6652d5ad-536d-4acb-a1a0-fbab11950b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/GEN_SCL_NAT-main/source'\n",
            "/content/drive/MyDrive/ColabNotebooks/GEN_SCL_NAT-main/source\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/GEN_SCL_NAT-main/source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqrOVPXvxf8s",
        "outputId": "2e5b2e14-3cb3-440c-e91c-231c66a3e1ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=1.10.0'                 figureE15.png      gen_scl_nat_main.py\n",
            " category_mappings.json   figureE1.png       \u001b[0m\u001b[01;34minference_outputs\u001b[0m/\n",
            " \u001b[01;34mdata\u001b[0m/                    figureE20.png      infer_restaurant.sh\n",
            " data_utils.py            figureE25.png      losses.py\n",
            " eval_utils.py            figureE30.png      Miniconda3-latest-Linux-x86_64.sh\n",
            " figure1.png              figureE5.png       \u001b[01;34m__pycache__\u001b[0m/\n",
            " figureE10.png            generate_data.py   utils.py\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp6rM14BfYIA",
        "outputId": "23d8467d-44cf-4267-a467-8ae57d9edbde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-26 09:42:49.786795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-26 09:42:50.652075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "acos_restaurant_dataIgen_scl_natIt5-baseIbeamsI5IwdI0.0Imax_epochsI40IesI0IaccI1IlrI9e-05Icont_lossI0.05Icont_tempI0.25ItruncIFalseIseedI123Irestaurant_output\n",
            "Global seed set to 123\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Sentiment distribution\n",
            "Counter({2: 928, 0: 433, 3: 123, 1: 46})\n",
            "Here is an example (from the train set):\n",
            "Input : judging from previous posts this used to be a good place, but not any longer.\n",
            "tensor([    3, 24331,    45,  1767,  3489,    48,   261,    12,    36,     3,\n",
            "            9,   207,   286,     3,     6,    68,    59,   136,  1200,     3,\n",
            "            5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Output: the restaurant overall | THE place IS not any longer | negative\n",
            "tensor([   8, 2062, 1879, 1820, 1853,  286, 6827,   59,  136, 1200, 1820, 2841,\n",
            "           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "\n",
            "****** Conducting Training ******\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus='1')` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices='1')` instead.\n",
            "  rank_zero_deprecation(\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: inference_outputs/acos_restaurant_dataIgen_scl_natIt5-baseIbeamsI5IwdI0.0Imax_epochsI40IesI0IaccI1IlrI9e-05Icont_lossI0.05Icont_tempI0.25ItruncIFalseIseedI123Irestaurant_output/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\n",
            "  | Name       | Type                       | Params\n",
            "----------------------------------------------------------\n",
            "0 | model      | T5ForConditionalGeneration | 222 M \n",
            "1 | cont_model | LinearModel                | 21.5 K\n",
            "2 | op_model   | LinearModel                | 21.5 K\n",
            "3 | as_model   | LinearModel                | 21.5 K\n",
            "4 | cat_model  | LinearModel                | 21.5 K\n",
            "----------------------------------------------------------\n",
            "222 M     Trainable params\n",
            "0         Non-trainable params\n",
            "222 M     Total params\n",
            "445.938   Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]Sentiment distribution\n",
            "Counter({2: 113, 0: 41, 3: 13, 1: 4})\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Sanity Checking DataLoader 0: 100% 2/2 [00:00<00:00,  2.40it/s]val_loss:\t tensor(9.8198, device='cuda:0')\n",
            "Sentiment distribution\n",
            "Counter({2: 928, 0: 433, 3: 123, 1: 46})\n",
            "Epoch 0:  66% 40/61 [00:23<00:12,  1.73it/s, loss=4.2, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  98% 60/61 [00:32<00:00,  1.85it/s, loss=4.2, v_num=0]\n",
            "Epoch 0: 100% 61/61 [00:32<00:00,  1.87it/s, loss=4.2, v_num=0]val_loss:\t tensor(2.6864, device='cuda:0')\n",
            "Epoch 0: 100% 61/61 [00:32<00:00,  1.87it/s, loss=3.51, v_num=0]\n",
            "Epoch 1:  66% 40/61 [00:23<00:12,  1.71it/s, loss=2.75, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  98% 60/61 [00:32<00:00,  1.82it/s, loss=2.75, v_num=0]\n",
            "Epoch 1: 100% 61/61 [00:32<00:00,  1.85it/s, loss=2.75, v_num=0]val_loss:\t tensor(2.3061, device='cuda:0')\n",
            "Epoch 1: 100% 61/61 [00:32<00:00,  1.85it/s, loss=2.69, v_num=0]\n",
            "Epoch 2:  66% 40/61 [00:24<00:12,  1.62it/s, loss=2.49, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  98% 60/61 [00:34<00:00,  1.76it/s, loss=2.49, v_num=0]\n",
            "Epoch 2: 100% 61/61 [00:34<00:00,  1.78it/s, loss=2.49, v_num=0]val_loss:\t tensor(2.2377, device='cuda:0')\n",
            "Epoch 2: 100% 61/61 [00:34<00:00,  1.78it/s, loss=2.5, v_num=0] \n",
            "Epoch 3:  66% 40/61 [00:23<00:12,  1.68it/s, loss=2.38, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  98% 60/61 [00:33<00:00,  1.79it/s, loss=2.38, v_num=0]\n",
            "Epoch 3: 100% 61/61 [00:33<00:00,  1.81it/s, loss=2.38, v_num=0]val_loss:\t tensor(2.2183, device='cuda:0')\n",
            "Epoch 3: 100% 61/61 [00:33<00:00,  1.81it/s, loss=2.37, v_num=0]\n",
            "Epoch 4:  66% 40/61 [00:24<00:12,  1.63it/s, loss=2.33, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  98% 60/61 [00:34<00:00,  1.75it/s, loss=2.33, v_num=0]\n",
            "Epoch 4: 100% 61/61 [00:34<00:00,  1.77it/s, loss=2.33, v_num=0]val_loss:\t tensor(2.1434, device='cuda:0')\n",
            "Epoch 4: 100% 61/61 [00:34<00:00,  1.77it/s, loss=2.33, v_num=0]\n",
            "Epoch 5:  66% 40/61 [00:24<00:12,  1.64it/s, loss=2.22, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  98% 60/61 [00:34<00:00,  1.76it/s, loss=2.22, v_num=0]\n",
            "Epoch 5: 100% 61/61 [00:34<00:00,  1.78it/s, loss=2.22, v_num=0]val_loss:\t tensor(2.1677, device='cuda:0')\n",
            "Epoch 5: 100% 61/61 [00:34<00:00,  1.78it/s, loss=2.21, v_num=0]\n",
            "Epoch 6:  66% 40/61 [00:24<00:12,  1.65it/s, loss=2.16, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  98% 60/61 [00:34<00:00,  1.74it/s, loss=2.16, v_num=0]\n",
            "Epoch 6: 100% 61/61 [00:34<00:00,  1.76it/s, loss=2.16, v_num=0]val_loss:\t tensor(2.1378, device='cuda:0')\n",
            "Epoch 6: 100% 61/61 [00:34<00:00,  1.76it/s, loss=2.15, v_num=0]\n",
            "Epoch 7:  66% 40/61 [00:24<00:12,  1.64it/s, loss=2.1, v_num=0] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  98% 60/61 [00:34<00:00,  1.75it/s, loss=2.1, v_num=0]\n",
            "Epoch 7: 100% 61/61 [00:34<00:00,  1.78it/s, loss=2.1, v_num=0]val_loss:\t tensor(2.1355, device='cuda:0')\n",
            "Epoch 7: 100% 61/61 [00:34<00:00,  1.78it/s, loss=2.11, v_num=0]\n",
            "Epoch 8:  66% 40/61 [00:24<00:12,  1.63it/s, loss=2.05, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  98% 60/61 [00:34<00:00,  1.74it/s, loss=2.05, v_num=0]\n",
            "Epoch 8: 100% 61/61 [00:34<00:00,  1.76it/s, loss=2.05, v_num=0]val_loss:\t tensor(2.1510, device='cuda:0')\n",
            "Epoch 8: 100% 61/61 [00:34<00:00,  1.76it/s, loss=2.04, v_num=0]\n",
            "Epoch 9:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.99, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  98% 60/61 [00:34<00:00,  1.74it/s, loss=1.99, v_num=0]\n",
            "Epoch 9: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.99, v_num=0]val_loss:\t tensor(2.1323, device='cuda:0')\n",
            "Epoch 9: 100% 61/61 [00:34<00:00,  1.76it/s, loss=2, v_num=0]   \n",
            "Epoch 10:  66% 40/61 [00:24<00:12,  1.64it/s, loss=1.99, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  98% 60/61 [00:34<00:00,  1.75it/s, loss=1.99, v_num=0]\n",
            "Epoch 10: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.99, v_num=0]val_loss:\t tensor(2.1525, device='cuda:0')\n",
            "Epoch 10: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.95, v_num=0]\n",
            "Epoch 11:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.96, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  98% 60/61 [00:34<00:00,  1.75it/s, loss=1.96, v_num=0]\n",
            "Epoch 11: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.96, v_num=0]val_loss:\t tensor(2.1633, device='cuda:0')\n",
            "Epoch 11: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.95, v_num=0]\n",
            "Epoch 12:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.93, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  98% 60/61 [00:34<00:00,  1.74it/s, loss=1.93, v_num=0]\n",
            "Epoch 12: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.93, v_num=0]val_loss:\t tensor(2.1750, device='cuda:0')\n",
            "Epoch 12: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.92, v_num=0]\n",
            "Epoch 13:  66% 40/61 [00:24<00:12,  1.62it/s, loss=1.9, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  98% 60/61 [00:34<00:00,  1.73it/s, loss=1.9, v_num=0]\n",
            "Epoch 13: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.9, v_num=0]val_loss:\t tensor(2.2133, device='cuda:0')\n",
            "Epoch 13: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.88, v_num=0]\n",
            "Epoch 14:  66% 40/61 [00:24<00:12,  1.64it/s, loss=1.88, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  98% 60/61 [00:34<00:00,  1.75it/s, loss=1.88, v_num=0]\n",
            "Epoch 14: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.88, v_num=0]val_loss:\t tensor(2.2101, device='cuda:0')\n",
            "Epoch 14: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.88, v_num=0]\n",
            "Epoch 15:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.87, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  98% 60/61 [00:34<00:00,  1.74it/s, loss=1.87, v_num=0]\n",
            "Epoch 15: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.87, v_num=0]val_loss:\t tensor(2.2550, device='cuda:0')\n",
            "Epoch 15: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.87, v_num=0]\n",
            "Epoch 16:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.86, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  98% 60/61 [00:34<00:00,  1.74it/s, loss=1.86, v_num=0]\n",
            "Epoch 16: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.86, v_num=0]val_loss:\t tensor(2.2483, device='cuda:0')\n",
            "Epoch 16: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.86, v_num=0]\n",
            "Epoch 17:  66% 40/61 [00:24<00:12,  1.62it/s, loss=1.84, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  98% 60/61 [00:34<00:00,  1.73it/s, loss=1.84, v_num=0]\n",
            "Epoch 17: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.84, v_num=0]val_loss:\t tensor(2.2592, device='cuda:0')\n",
            "Epoch 17: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.86, v_num=0]\n",
            "Epoch 18:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.84, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18:  98% 60/61 [00:34<00:00,  1.73it/s, loss=1.84, v_num=0]\n",
            "Epoch 18: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.84, v_num=0]val_loss:\t tensor(2.2679, device='cuda:0')\n",
            "Epoch 18: 100% 61/61 [00:34<00:00,  1.76it/s, loss=1.82, v_num=0]\n",
            "Epoch 19:  66% 40/61 [00:24<00:12,  1.63it/s, loss=1.83, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  98% 60/61 [00:34<00:00,  1.75it/s, loss=1.83, v_num=0]\n",
            "Epoch 19: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.83, v_num=0]val_loss:\t tensor(2.2808, device='cuda:0')\n",
            "Epoch 19: 100% 61/61 [00:34<00:00,  1.77it/s, loss=1.81, v_num=0]\n",
            "Epoch 20:   0% 0/61 [00:00<?, ?it/s, loss=1.81, v_num=0]"
          ]
        }
      ],
      "source": [
        "!python gen_scl_nat_main.py \\\n",
        "   --task gen_scl_nat \\\n",
        "   --do_train\\\n",
        "   --do_direct_eval\\\n",
        "   --dataset \\acos_restaurant_data \\\n",
        "   --model_name_or_path t5-base \\\n",
        "   --output_folder inference_outputs \\\n",
        "   --n_gpu 1 \\\n",
        "   --train_batch_size 28 \\\n",
        "   --eval_batch_size 28 \\\n",
        "   --learning_rate 9e-5 \\\n",
        "   --gradient_accumulation_steps 1 \\\n",
        "   --num_train_epochs 40 \\\n",
        "   --num_beams 5 \\\n",
        "   --weight_decay 0.0 \\\n",
        "   --seed 123 \\\n",
        "   --cont_loss 0.05 \\\n",
        "   --cont_temp 0.25 \\\n",
        "   --model_prefix restaurant_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzSP6LVCfec_"
      },
      "outputs": [],
      "source": [
        "!python gen_scl_nat_main.py \\\n",
        "   --task gen_scl_nat \\\n",
        "   --do_train\\\n",
        "   --dataset \\acos_restaurant_data \\\n",
        "   --model_name_or_path t5-base \\\n",
        "   --output_folder inference_outputs \\\n",
        "   --n_gpu 1 \\\n",
        "   --train_batch_size 16 \\\n",
        "   --eval_batch_size 16 \\\n",
        "   --learning_rate 9e-5 \\\n",
        "   --gradient_accumulation_steps 1 \\\n",
        "   --num_train_epochs 1 \\\n",
        "   --num_beams 5 \\\n",
        "   --weight_decay 0.0 \\\n",
        "   --seed 123 \\\n",
        "   --cont_loss 0.05 \\\n",
        "   --cont_temp 0.25 \\\n",
        "   --model_prefix restaurant_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ais2fvXyxd3l"
      },
      "source": [
        "# 新段落"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}